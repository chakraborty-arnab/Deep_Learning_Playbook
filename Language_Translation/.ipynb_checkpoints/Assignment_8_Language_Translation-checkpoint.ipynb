{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60f01d73",
   "metadata": {
    "id": "60f01d73"
   },
   "source": [
    "# Assignment 8 - Language Translation (English - Hindi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe09020e",
   "metadata": {
    "id": "fe09020e"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from string import digits\n",
    "import tensorflow as tf\n",
    "import re\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22PwPG4scIZ8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "22PwPG4scIZ8",
    "outputId": "71a502e8-4727-4801-a4fe-8104c90ef652"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[1;32m      2\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b75bf4",
   "metadata": {
    "id": "a5b75bf4"
   },
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0876f352",
   "metadata": {
    "id": "0876f352"
   },
   "outputs": [],
   "source": [
    "# !pip install datasets==1.18.1\n",
    "\n",
    "# ## Please ensure you have executed this at least once."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ace541e",
   "metadata": {
    "id": "9ace541e"
   },
   "source": [
    "## Download Parallel Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8602ba1d",
   "metadata": {
    "id": "8602ba1d"
   },
   "outputs": [],
   "source": [
    "#from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5b3bf1",
   "metadata": {
    "id": "7b5b3bf1"
   },
   "outputs": [],
   "source": [
    "#dataset = load_dataset(\"cfilt/iitb-english-hindi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8e1bb8",
   "metadata": {
    "id": "aa8e1bb8"
   },
   "source": [
    "## Extract Dataset in Source and Target Text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a11dec2",
   "metadata": {
    "id": "7a11dec2"
   },
   "outputs": [],
   "source": [
    "# source_train_file = open(\"source_train.txt\", \"w+\", encoding='utf8')\n",
    "# target_train_file = open(\"target_train.txt\", \"w+\", encoding='utf8')\n",
    "# for translation_pair in dataset[\"train\"][\"translation\"]:\n",
    "#   source_sentence = translation_pair[\"en\"]\n",
    "#   target_sentence = translation_pair[\"hi\"]\n",
    "#   source_train_file.write(source_sentence.strip(\"\\n\") + \"\\n\")\n",
    "#   target_train_file.write(target_sentence.strip(\"\\n\") + \"\\n\")\n",
    "# source_train_file.close()\n",
    "# target_train_file.close()\n",
    "\n",
    "# source_valid_file = open(\"source_valid.txt\", \"w+\", encoding='utf8')\n",
    "# target_valid_file = open(\"target_valid.txt\", \"w+\", encoding='utf8')\n",
    "# for translation_pair in dataset[\"validation\"][\"translation\"]:\n",
    "#   source_sentence = translation_pair[\"en\"]\n",
    "#   target_sentence = translation_pair[\"hi\"]\n",
    "#   source_valid_file.write(source_sentence.strip(\"\\n\") + \"\\n\")\n",
    "#   target_valid_file.write(target_sentence.strip(\"\\n\") + \"\\n\")\n",
    "# source_valid_file.close()\n",
    "# target_valid_file.close()\n",
    "\n",
    "# source_test_file = open(\"source_test.txt\", \"w+\", encoding='utf8')\n",
    "# target_test_file = open(\"target_test.txt\", \"w+\", encoding='utf8')\n",
    "# for translation_pair in dataset[\"test\"][\"translation\"]:\n",
    "#   source_sentence = translation_pair[\"en\"]\n",
    "#   target_sentence = translation_pair[\"hi\"]\n",
    "#   source_test_file.write(source_sentence.strip(\"\\n\") + \"\\n\")\n",
    "#   target_test_file.write(target_sentence.strip(\"\\n\") + \"\\n\")\n",
    "# source_test_file.close()\n",
    "# target_test_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68788062",
   "metadata": {
    "id": "68788062"
   },
   "source": [
    "## Read language text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "emPJqrQ5XO5_",
   "metadata": {
    "id": "emPJqrQ5XO5_"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('hind-eng_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "HhR5OgvOJQLL",
   "metadata": {
    "id": "HhR5OgvOJQLL"
   },
   "outputs": [],
   "source": [
    "df['hindi']=df['hindi'].replace('।','',regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bH817kH0Jjat",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "bH817kH0Jjat",
    "outputId": "1e37e72b-f784-4075-d702-f1a25be2817b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'आप जिस वाक्य का अनुवाद कर रहे हैं COMMA उस ही का अच्छी तरह से अनुवाद करें दूसरी भाषाओं के अनुवादों से प्रभावित न होने दें'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.hindi.values[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "mxdmW0Z0bzLj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "mxdmW0Z0bzLj",
    "outputId": "80920d39-6cf2-4fb4-b398-c5dbc4ed7faf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'make a good translation of the sentence that you are translating dont let translations into other languages influence you'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.english.values[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "011fcb30",
   "metadata": {
    "id": "011fcb30"
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # File paths\n",
    "# english_sentences = \"source_train.txt\"\n",
    "# hindi_sentences = \"target_train.txt\"\n",
    "\n",
    "# # Reading the source and target files\n",
    "# with open(english_sentences, \"r\", encoding='utf-8') as file:\n",
    "#     english_sentences = file.readlines()\n",
    "\n",
    "# with open(hindi_sentences, \"r\", encoding='utf-8') as file:\n",
    "#     hindi_sentences = file.readlines()\n",
    "\n",
    "# # Removing newline characters and any leading/trailing whitespace\n",
    "# english_sentences = [s.strip() for s in english_sentences]\n",
    "# hindi_sentences = [t.strip() for t in hindi_sentences]\n",
    "\n",
    "# # Creating a DataFrame\n",
    "# df_main = pd.DataFrame({\n",
    "#     \"english\": english_sentences,\n",
    "#     \"hindi\": hindi_sentences\n",
    "# })\n",
    "\n",
    "# # Display the first few rows of the DataFrame\n",
    "# df_main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f33436",
   "metadata": {
    "id": "13f33436"
   },
   "source": [
    "## Preprocess text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3c24c58",
   "metadata": {
    "id": "e3c24c58"
   },
   "outputs": [],
   "source": [
    "# import re\n",
    "\n",
    "# def preprocess_sentence(sentence, language='eng'):\n",
    "\n",
    "#     # Convert to lowercase\n",
    "#     sentence = sentence.lower()\n",
    "#     # Replace ',' with 'COMMA'\n",
    "#     sentence = sentence.replace(',', ' COMMA')\n",
    "\n",
    "#     if language == 'eng':\n",
    "#         # Retain only English letters and spaces, replace everything else\n",
    "#         sentence = re.sub(r'[^a-z COMMA]', '', sentence)\n",
    "#     else:\n",
    "#         # Retain only Hindi characters, common punctuation, spaces, and COMMA\n",
    "#         sentence = re.sub(r'[^\\u0900-\\u097F\\s COMMA]', '', sentence)\n",
    "\n",
    "#     return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0381c61",
   "metadata": {
    "id": "b0381c61"
   },
   "outputs": [],
   "source": [
    "# # Applying preprocessing to the lists of sentences\n",
    "# preprocessed_english_sentences = [preprocess_sentence(sentence, 'eng') for sentence in english_sentences]\n",
    "# preprocessed_hindi_sentences = [preprocess_sentence(sentence, 'hi') for sentence in hindi_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b6601ad",
   "metadata": {
    "id": "4b6601ad"
   },
   "outputs": [],
   "source": [
    "# # Creating a DataFrame\n",
    "# df_preprocessed = pd.DataFrame({\n",
    "#     \"English\": preprocessed_english_sentences,\n",
    "#     \"Hindi\": preprocessed_hindi_sentences\n",
    "# })\n",
    "\n",
    "# # Displaying the DataFrame\n",
    "# df_preprocessed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed816f40",
   "metadata": {
    "id": "ed816f40"
   },
   "source": [
    "## Filter to only keep sentences with word counts between 10 to 100 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "Jiy4rLru-iIl",
   "metadata": {
    "id": "Jiy4rLru-iIl"
   },
   "outputs": [],
   "source": [
    "df_preprocessed = df[['english','hindi']].rename(columns={'english':'English','hindi':'Hindi'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57b60138",
   "metadata": {
    "id": "57b60138"
   },
   "outputs": [],
   "source": [
    "# Filter the DataFrame to only keep sentences with word counts between 10 to 100 words\n",
    "filtered_df_by_word_count = df_preprocessed[\n",
    "    (df_preprocessed['English'].str.split().str.len() >= 5) &\n",
    "    (df_preprocessed['English'].str.split().str.len() <= 100) &\n",
    "    (df_preprocessed['Hindi'].str.split().str.len() >= 5) &\n",
    "    (df_preprocessed['Hindi'].str.split().str.len() <= 100)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29bfb67c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "29bfb67c",
    "outputId": "446df2ec-5817-4cff-ab30-7a3b7109311e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>Hindi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>he has a hat on</td>\n",
       "      <td>उसने टोपी पहनी हुई है</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no COMMA i didnt go</td>\n",
       "      <td>नहीं COMMA मैं नहीं गया था</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>he came to see me</td>\n",
       "      <td>वह मुझसे मिलने आया था</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>he is after a job</td>\n",
       "      <td>वह किसी नौकरी के पीछे पड़ा है</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i can drive a car</td>\n",
       "      <td>मैं गाड़ी चला सकता हूँ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2085</th>\n",
       "      <td>the passengers who were injured in the acciden...</td>\n",
       "      <td>जिन यात्रियों को दुर्घटना मे चोट आई थी उन्हे अ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2086</th>\n",
       "      <td>democracy is the worst form of government COMM...</td>\n",
       "      <td>लोकतंत्र सरकार का सबसे घिनौना रूप है COMMA अगर...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2087</th>\n",
       "      <td>if my boy had not been killed in the traffic a...</td>\n",
       "      <td>अगर मेरा बेटा ट्रेफ़िक हादसे में नहीं मारा गया...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2088</th>\n",
       "      <td>when i was a kid COMMA touching bugs didnt bot...</td>\n",
       "      <td>जब मैं बच्चा था COMMA मुझे कीड़ों को छूने से क...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2089</th>\n",
       "      <td>make a good translation of the sentence that y...</td>\n",
       "      <td>आप जिस वाक्य का अनुवाद कर रहे हैं COMMA उस ही ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2090 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                English  \\\n",
       "0                                       he has a hat on   \n",
       "1                                   no COMMA i didnt go   \n",
       "2                                     he came to see me   \n",
       "3                                     he is after a job   \n",
       "4                                     i can drive a car   \n",
       "...                                                 ...   \n",
       "2085  the passengers who were injured in the acciden...   \n",
       "2086  democracy is the worst form of government COMM...   \n",
       "2087  if my boy had not been killed in the traffic a...   \n",
       "2088  when i was a kid COMMA touching bugs didnt bot...   \n",
       "2089  make a good translation of the sentence that y...   \n",
       "\n",
       "                                                  Hindi  \n",
       "0                                 उसने टोपी पहनी हुई है  \n",
       "1                            नहीं COMMA मैं नहीं गया था  \n",
       "2                                 वह मुझसे मिलने आया था  \n",
       "3                         वह किसी नौकरी के पीछे पड़ा है  \n",
       "4                                मैं गाड़ी चला सकता हूँ  \n",
       "...                                                 ...  \n",
       "2085  जिन यात्रियों को दुर्घटना मे चोट आई थी उन्हे अ...  \n",
       "2086  लोकतंत्र सरकार का सबसे घिनौना रूप है COMMA अगर...  \n",
       "2087  अगर मेरा बेटा ट्रेफ़िक हादसे में नहीं मारा गया...  \n",
       "2088  जब मैं बच्चा था COMMA मुझे कीड़ों को छूने से क...  \n",
       "2089  आप जिस वाक्य का अनुवाद कर रहे हैं COMMA उस ही ...  \n",
       "\n",
       "[2090 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df_by_word_count.reset_index(drop=True, inplace=True)\n",
    "\n",
    "filtered_df_by_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e733530",
   "metadata": {
    "id": "4e733530"
   },
   "outputs": [],
   "source": [
    "lines = filtered_df_by_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7f0e93b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f7f0e93b",
    "outputId": "ceb47cb2-a251-4be4-f01e-27c4c155c8fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                English  \\\n",
      "0                                       he has a hat on   \n",
      "1                                   no COMMA i didnt go   \n",
      "2                                     he came to see me   \n",
      "3                                     he is after a job   \n",
      "4                                     i can drive a car   \n",
      "...                                                 ...   \n",
      "2085  the passengers who were injured in the acciden...   \n",
      "2086  democracy is the worst form of government COMM...   \n",
      "2087  if my boy had not been killed in the traffic a...   \n",
      "2088  when i was a kid COMMA touching bugs didnt bot...   \n",
      "2089  make a good translation of the sentence that y...   \n",
      "\n",
      "                                                  Hindi  \n",
      "0                                 उसने टोपी पहनी हुई है  \n",
      "1                            नहीं COMMA मैं नहीं गया था  \n",
      "2                                 वह मुझसे मिलने आया था  \n",
      "3                         वह किसी नौकरी के पीछे पड़ा है  \n",
      "4                                मैं गाड़ी चला सकता हूँ  \n",
      "...                                                 ...  \n",
      "2085  जिन यात्रियों को दुर्घटना मे चोट आई थी उन्हे अ...  \n",
      "2086  लोकतंत्र सरकार का सबसे घिनौना रूप है COMMA अगर...  \n",
      "2087  अगर मेरा बेटा ट्रेफ़िक हादसे में नहीं मारा गया...  \n",
      "2088  जब मैं बच्चा था COMMA मुझे कीड़ों को छूने से क...  \n",
      "2089  आप जिस वाक्य का अनुवाद कर रहे हैं COMMA उस ही ...  \n",
      "\n",
      "[2090 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac979825",
   "metadata": {
    "id": "ac979825"
   },
   "source": [
    "Add Start and end tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec04394",
   "metadata": {
    "id": "fec04394"
   },
   "source": [
    "## Tokenize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa7d3e36",
   "metadata": {
    "id": "fa7d3e36"
   },
   "outputs": [],
   "source": [
    "def preprocess_sentence(w):\n",
    "    w = w.strip()\n",
    "\n",
    "    # adding a start and an end token to the sentence\n",
    "    # so that the model know when to start and stop predicting.\n",
    "    w = '<start> ' + w + ' <end>'\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef99dff",
   "metadata": {
    "id": "6ef99dff"
   },
   "source": [
    "In Transformer, we add beginning and end of sentence sentinels to *both* languages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "063511bd",
   "metadata": {
    "id": "063511bd"
   },
   "outputs": [],
   "source": [
    "def create_full_dataset():\n",
    "    sentence_pairs = [[preprocess_sentence(l[0]), preprocess_sentence(l[1])] for l in lines.values]\n",
    "    return zip(*sentence_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9511dffe",
   "metadata": {
    "id": "9511dffe"
   },
   "outputs": [],
   "source": [
    "def tokenize(lang):\n",
    "    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "    lang_tokenizer.fit_on_texts(lang)\n",
    "\n",
    "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
    "\n",
    "    return tensor, lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "661f22ab",
   "metadata": {
    "id": "661f22ab"
   },
   "outputs": [],
   "source": [
    "def load_full_dataset():\n",
    "    # creating cleaned input, output pairs\n",
    "    inp_lang, targ_lang = create_full_dataset()\n",
    "\n",
    "    input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
    "    target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
    "\n",
    "    return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "436a8481",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "436a8481",
    "outputId": "771b845a-b4a0-4a4c-c3c7-fdb0c9cf8d04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> he has a hat on <end>\n",
      "<start> उसने टोपी पहनी हुई है <end>\n"
     ]
    }
   ],
   "source": [
    "en, hi = create_full_dataset()\n",
    "print(en[0])\n",
    "print(hi[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35d3b33",
   "metadata": {
    "id": "a35d3b33"
   },
   "source": [
    "Load the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "01fd62f7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "01fd62f7",
    "outputId": "64250ba5-69a4-403e-accf-19b8a09c217e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29, 25)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_examples = len(lines)\n",
    "input_tensor, target_tensor, inp_lang, targ_lang = load_full_dataset()\n",
    "\n",
    "# Calculate max_length of the target tensors\n",
    "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]\n",
    "max_length_targ, max_length_inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "64fc5b91",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "64fc5b91",
    "outputId": "c678157d-6129-42d3-f91a-933e8e6c0a3c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2090, 25), (2090, 29))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor.shape, target_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "36321b37",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "36321b37",
    "outputId": "8fdcab84-4bce-42e6-89ca-e9926b003914"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 words in the Input Language vocabulary:\n",
      "<start>\n",
      "<end>\n",
      "the\n",
      "to\n",
      "i\n",
      "you\n",
      "a\n",
      "is\n",
      "he\n",
      "of\n",
      "First 10 words in the Target Language vocabulary:\n",
      "<start>\n",
      "<end>\n",
      "है\n",
      "में\n",
      "नहीं\n",
      "वह\n",
      "से\n",
      "मैं\n",
      "के\n",
      "को\n"
     ]
    }
   ],
   "source": [
    "# Function to print vocabulary words\n",
    "def print_vocab_words(tokenizer, language_name, num_words=10):\n",
    "    # Extract the word_index from the tokenizer\n",
    "    word_index = tokenizer.word_index\n",
    "\n",
    "    # Get the first 'num_words' words from the vocabulary\n",
    "    first_words = list(word_index.keys())[:num_words]\n",
    "\n",
    "    print(f\"First {num_words} words in the {language_name} vocabulary:\")\n",
    "    for word in first_words:\n",
    "        print(word)\n",
    "\n",
    "# 'inp_lang' and 'targ_lang' are tokenizer objects for input and target languages, respectively\n",
    "print_vocab_words(inp_lang, \"Input Language\")\n",
    "print_vocab_words(targ_lang, \"Target Language\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b80f0a9e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b80f0a9e",
    "outputId": "1946e1c1-cad0-4bf5-8681-85f13d429457"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input language vocabulary size: 2156\n",
      "Target language vocabulary size: 2556\n"
     ]
    }
   ],
   "source": [
    "# Vocabulary size for the input language\n",
    "input_vocab_size = len(inp_lang.word_index) + 1  # Adding 1 because indexing starts from 1\n",
    "print(f\"Input language vocabulary size: {input_vocab_size}\")\n",
    "\n",
    "# Vocabulary size for the target language\n",
    "target_vocab_size = len(targ_lang.word_index) + 1  # Adding 1 because indexing starts from 1\n",
    "print(f\"Target language vocabulary size: {target_vocab_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e000fc2e",
   "metadata": {
    "id": "e000fc2e"
   },
   "source": [
    "## Train and validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4eb4c81e",
   "metadata": {
    "id": "4eb4c81e"
   },
   "outputs": [],
   "source": [
    "# Select the first 50,000 samples\n",
    "# input_tensor_mini = input_tensor[:10000]\n",
    "input_tensor_mini = input_tensor\n",
    "# target_tensor_mini = target_tensor[:10000]\n",
    "target_tensor_mini = target_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e2e63f5b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e2e63f5b",
    "outputId": "2d99f0d5-959b-47ce-b02b-0c52a47abe79"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1881, 25), (209, 25), (1881, 29), (209, 29))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating training and validation sets using an 90-10 split\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(\n",
    "    input_tensor_mini, target_tensor_mini, test_size=0.1)\n",
    "\n",
    "input_tensor_train.shape, input_tensor_val.shape, target_tensor_train.shape, target_tensor_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "77473ee8",
   "metadata": {
    "id": "77473ee8"
   },
   "outputs": [],
   "source": [
    "def convert(lang, tensor):\n",
    "    for t in tensor:\n",
    "        if t!=0:\n",
    "            print (\"%d ----> %s\" % (t, lang.index_word[t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2cc65cfe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2cc65cfe",
    "outputId": "baf4bf7f-9cfa-4e1c-a377-b85a6a933ecb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Language; index to word mapping\n",
      "1 ----> <start>\n",
      "21 ----> do\n",
      "6 ----> you\n",
      "50 ----> know\n",
      "31 ----> your\n",
      "350 ----> size\n",
      "2 ----> <end>\n",
      "\n",
      "Target Language; index to word mapping\n",
      "1 ----> <start>\n",
      "14 ----> क्या\n",
      "132 ----> आपको\n",
      "84 ----> अपना\n",
      "382 ----> नाप\n",
      "67 ----> पता\n",
      "3 ----> है\n",
      "2 ----> <end>\n"
     ]
    }
   ],
   "source": [
    "print (\"Input Language; index to word mapping\")\n",
    "convert(inp_lang, input_tensor_train[1])\n",
    "print ()\n",
    "print (\"Target Language; index to word mapping\")\n",
    "convert(targ_lang, target_tensor_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9c1bce3a",
   "metadata": {
    "id": "9c1bce3a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-03 14:46:21.890074: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3 Pro\n",
      "2024-04-03 14:46:21.890142: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 18.00 GB\n",
      "2024-04-03 14:46:21.890156: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 6.00 GB\n",
      "2024-04-03 14:46:21.890282: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-04-03 14:46:21.890761: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 16\n",
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "\n",
    "vocab_inp_size = len(inp_lang.word_index)+1\n",
    "vocab_tar_size = len(targ_lang.word_index)+1\n",
    "\n",
    "dataset_train = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset_train = dataset_train.batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "dataset_val = tf.data.Dataset.from_tensor_slices((input_tensor_val, target_tensor_val)).shuffle(BUFFER_SIZE)\n",
    "dataset_val = dataset_val.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "31803de3",
   "metadata": {
    "id": "31803de3"
   },
   "outputs": [],
   "source": [
    "train_dataset = dataset_train\n",
    "val_dataset = dataset_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3a25a55d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3a25a55d",
    "outputId": "16d31346-37bc-4d0e-effe-f5c4f31b1982"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_BatchDataset element_spec=(TensorSpec(shape=(16, 25), dtype=tf.int32, name=None), TensorSpec(shape=(16, 29), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "15e3886c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "15e3886c",
    "outputId": "5750335a-ead0-420a-f770-7543a3dbe213"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_BatchDataset element_spec=(TensorSpec(shape=(16, 25), dtype=tf.int32, name=None), TensorSpec(shape=(16, 29), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b79378",
   "metadata": {
    "id": "42b79378"
   },
   "source": [
    "## Positional encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fb4a6ee2",
   "metadata": {
    "id": "fb4a6ee2"
   },
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "    return pos * angle_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "00a2f21a",
   "metadata": {
    "id": "00a2f21a"
   },
   "outputs": [],
   "source": [
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                          np.arange(d_model)[np.newaxis, :],\n",
    "                          d_model)\n",
    "\n",
    "    # apply sin to even indices in the array; 2i\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "\n",
    "    # apply cos to odd indices in the array; 2i+1\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8c6730",
   "metadata": {
    "id": "9d8c6730"
   },
   "source": [
    "## Masking pad tokens in the input and future tokens in the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7f8e13e3",
   "metadata": {
    "id": "7f8e13e3"
   },
   "outputs": [],
   "source": [
    "def create_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "\n",
    "    # add extra dimensions to add the padding\n",
    "    # to the attention logits.\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6379d98d",
   "metadata": {
    "id": "6379d98d"
   },
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask  # (seq_len, seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387f49f7",
   "metadata": {
    "id": "387f49f7"
   },
   "source": [
    "## Scaled dot product attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d9f7d3e3",
   "metadata": {
    "id": "d9f7d3e3"
   },
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    \"\"\"Calculate the attention weights.\n",
    "    q, k, v must have matching leading dimensions.\n",
    "    k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
    "    The mask has different shapes depending on its type(padding or look ahead)\n",
    "    but it must be broadcastable for addition.\n",
    "\n",
    "    Args:\n",
    "    q: query shape == (..., seq_len_q, depth)\n",
    "    k: key shape == (..., seq_len_k, depth)\n",
    "    v: value shape == (..., seq_len_v, depth_v)\n",
    "    mask: Float tensor with shape broadcastable\n",
    "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "    output, attention_weights\n",
    "    \"\"\"\n",
    "\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "    # scale matmul_qk\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "    # add the mask to the scaled tensor.\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)\n",
    "\n",
    "    # softmax is normalized on the last axis (seq_len_k) so that the scores add up to 1.\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "    output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed413825",
   "metadata": {
    "id": "ed413825"
   },
   "source": [
    "## Multi-head attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "000fecda",
   "metadata": {
    "id": "000fecda"
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.wq = tf.keras.layers.Dense(d_model)\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        self.wv = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"Split the last dimension into (num_heads, depth).\n",
    "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "        \"\"\"\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "\n",
    "        q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "        k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "        v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "\n",
    "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "\n",
    "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "            q, k, v, mask)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "\n",
    "        concat_attention = tf.reshape(scaled_attention,\n",
    "                                      (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc23a930",
   "metadata": {
    "id": "cc23a930"
   },
   "source": [
    "## Pointwise feed forward network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9cac212e",
   "metadata": {
    "id": "9cac212e"
   },
   "outputs": [],
   "source": [
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "    return tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
    "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd2a9b7",
   "metadata": {
    "id": "1cd2a9b7"
   },
   "source": [
    "# Encoder and decoder\n",
    "\n",
    "Now we're ready to talk about the encoder and decoder. In that, the transformer model follows the same general pattern as our standard sequence to sequence with attention model, albeit with multiple layers:\n",
    "\n",
    "* The input sentence is passed through `N` encoder layers that generate an output for each word/token in the sequence.\n",
    "* The decoder attends on the encoder's output and its own input (self-attention) to predict the next word.\n",
    "\n",
    "## Encoder layer\n",
    "\n",
    "Each encoder layer consists of sublayers:\n",
    "\n",
    "1. Multi-head attention (with padding mask)\n",
    "2. Pointwise feed forward networks\n",
    "\n",
    "Each of these sublayers has a residual connection around it followed by a layer normalization. Residual connections help in avoiding the vanishing gradient problem in deep networks.\n",
    "\n",
    "The output of each sublayer is `LayerNorm(x + Sublayer(x))`. The normalization is done on the `d_model` (last) axis. There are N encoder layers in the transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "43da4792",
   "metadata": {
    "id": "43da4792"
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, training, mask):\n",
    "        attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        return out2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23d11bf",
   "metadata": {
    "id": "a23d11bf"
   },
   "source": [
    "## Decoder layer\n",
    "\n",
    "Each decoder layer consists of sublayers:\n",
    "\n",
    "1. Masked multi-head attention (with look ahead mask and padding mask)\n",
    "2. Multi-head attention (with padding mask): V (value) and K (key) receive the *encoder output* as inputs. Q (query) receives the *output from the masked multi-head attention sublayer.*\n",
    "3. Pointwise feed forward networks\n",
    "\n",
    "Each of these sublayers has a residual connection around it followed by a layer normalization. The output of each sublayer is `LayerNorm(x + Sublayer(x))`. The normalization is done on the `d_model` (last) axis.\n",
    "\n",
    "There are N decoder layers in the transformer.\n",
    "\n",
    "As Q receives the output from decoder's first attention block, and K receives the encoder output, the attention weights represent the importance given to the decoder's input based on the encoder's output. In other words, the decoder predicts the next word by looking at the encoder output and self-attending to its own output. See the demonstration above in the scaled dot product attention section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ef91485d",
   "metadata": {
    "id": "ef91485d"
   },
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "\n",
    "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
    "        # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
    "        attn1 = self.dropout1(attn1, training=training)\n",
    "        out1 = self.layernorm1(attn1 + x)\n",
    "\n",
    "        attn2, attn_weights_block2 = self.mha2(\n",
    "            enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
    "        attn2 = self.dropout2(attn2, training=training)\n",
    "        out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
    "        ffn_output = self.dropout3(ffn_output, training=training)\n",
    "        out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        return out3, attn_weights_block1, attn_weights_block2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ac7bee",
   "metadata": {
    "id": "99ac7bee"
   },
   "source": [
    "## Encoder\n",
    "\n",
    "And now we can talk about the encoder.\n",
    "\n",
    "The `Encoder` consists of:\n",
    "1.   Word2vec semantic embedding\n",
    "2.   Positional Encoding\n",
    "3.   N encoder layers (what we coded above)\n",
    "\n",
    "The input is fed through an embedding which is then summed with  positional encoding. The output of this summation is the input to the encoder layers. The output of the encoder is the input to the decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5e9ef996",
   "metadata": {
    "id": "5e9ef996"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding,\n",
    "                                                self.d_model)\n",
    "\n",
    "\n",
    "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate)\n",
    "                           for _ in range(num_layers)]\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, training, mask):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "\n",
    "        # adding embedding and position encoding.\n",
    "        x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x, training, mask)\n",
    "\n",
    "        return x  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02b2065",
   "metadata": {
    "id": "d02b2065"
   },
   "source": [
    "## Decoder\n",
    "\n",
    " The `Decoder` consists of:\n",
    "1.   Word2vec embedding of the target sequence\n",
    "2.   Positional Encoding\n",
    "3.   N decoder layers\n",
    "\n",
    "The target sequence is fed through an embedding and summed with positional encoding. The output of this summation is the input to the decoder layers. The output of the decoder is the input to our final linear layer, which we mention in the wrapper Transformer layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ea9cbeaf",
   "metadata": {
    "id": "ea9cbeaf"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "\n",
    "        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate)\n",
    "                           for _ in range(num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, enc_output, training,\n",
    "           look_ahead_mask, padding_mask):\n",
    "\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        attention_weights = {}\n",
    "\n",
    "        x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
    "                                                 look_ahead_mask, padding_mask)\n",
    "\n",
    "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
    "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
    "\n",
    "        # x.shape == (batch_size, target_seq_len, d_model)\n",
    "        return x, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f0b018",
   "metadata": {
    "id": "d9f0b018"
   },
   "source": [
    "## Create the Transformer\n",
    "\n",
    "Transformer consists of the encoder, decoder and our final affine (linear) `Dense` layer. The output of the decoder is the input to the linear layer and its output is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ae76755f",
   "metadata": {
    "id": "ae76755f"
   },
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "               target_vocab_size, pe_input, pe_target, rate=0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(num_layers, d_model, num_heads, dff,\n",
    "                               input_vocab_size, pe_input, rate)\n",
    "\n",
    "        self.decoder = Decoder(num_layers, d_model, num_heads, dff,\n",
    "                               target_vocab_size, pe_target, rate)\n",
    "\n",
    "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "\n",
    "    def call(self, inp, tar, training, enc_padding_mask,\n",
    "           look_ahead_mask, dec_padding_mask):\n",
    "\n",
    "        enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
    "\n",
    "        # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
    "        dec_output, attention_weights = self.decoder(\n",
    "            tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
    "\n",
    "        final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
    "\n",
    "        return final_output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e57579",
   "metadata": {
    "id": "55e57579"
   },
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "695d2f1c",
   "metadata": {
    "id": "695d2f1c"
   },
   "outputs": [],
   "source": [
    "num_layers = 4\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "input_vocab_size = len(inp_lang.word_index) + 1\n",
    "target_vocab_size = len(targ_lang.word_index) + 1\n",
    "dropout_rate = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5a1bed",
   "metadata": {
    "id": "5a5a1bed"
   },
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5dc94612",
   "metadata": {
    "id": "5dc94612"
   },
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        step = tf.cast(step, tf.float32)\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8e4679c8",
   "metadata": {
    "id": "8e4679c8"
   },
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.legacy.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n",
    "                                     epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9fb393a3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "9fb393a3",
    "outputId": "d93ed856-7d90-4945-9d31-d8682b48cc8e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp_learning_rate_schedule = CustomSchedule(d_model)\n",
    "\n",
    "plt.plot(temp_learning_rate_schedule(tf.range(40000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4042b49a",
   "metadata": {
    "id": "4042b49a"
   },
   "source": [
    "## Loss and metrics\n",
    "\n",
    "Since the target sequences are padded, it is important to apply a padding mask when calculating the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e838e0d9",
   "metadata": {
    "id": "e838e0d9"
   },
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "687f573b",
   "metadata": {
    "id": "687f573b"
   },
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "52da641e",
   "metadata": {
    "id": "52da641e"
   },
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "    name='train_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95647e0d",
   "metadata": {
    "id": "95647e0d"
   },
   "source": [
    "## Training and checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6cbefd37",
   "metadata": {
    "id": "6cbefd37"
   },
   "outputs": [],
   "source": [
    "transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
    "                          input_vocab_size, target_vocab_size,\n",
    "                          pe_input=input_vocab_size,\n",
    "                          pe_target=target_vocab_size,\n",
    "                          rate=dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "985aac85",
   "metadata": {
    "id": "985aac85"
   },
   "outputs": [],
   "source": [
    "def create_masks(inp, tar):\n",
    "    # Encoder padding mask\n",
    "    enc_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    # Used in the 2nd attention block in the decoder.\n",
    "    # This padding mask is used to mask the encoder outputs.\n",
    "    dec_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    # Used in the 1st attention block in the decoder.\n",
    "    # It is used to pad and mask future tokens in the input received by\n",
    "    # the decoder.\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "    dec_target_padding_mask = create_padding_mask(tar)\n",
    "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "\n",
    "    return enc_padding_mask, combined_mask, dec_padding_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa4a9eb",
   "metadata": {
    "id": "eaa4a9eb"
   },
   "source": [
    "Create the checkpoint path and the checkpoint manager. This will be used to save checkpoints every `n` epochs.\n",
    "\n",
    "Create the `transformer` folder in your `~/data/training_checkpoints` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "07c211c0",
   "metadata": {
    "id": "07c211c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest checkpoint restored!!\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = \"training_checkpoints/transformer\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
    "                           optimizer=optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print ('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6b81dd",
   "metadata": {
    "id": "bc6b81dd"
   },
   "source": [
    "The target is divided into `tar_inp` and `tar_real`. `tar_inp` is passed as an input to the decoder. `tar_real` is that same input shifted by 1: At each location in `tar_input`, `tar_real` contains the  next token that should be predicted.\n",
    "\n",
    "For example, `sentence` = \"<start> A lion in the jungle is sleeping <end>\"\n",
    "\n",
    "`tar_inp` =  `<start> A lion in the jungle is sleeping`\n",
    "\n",
    "`tar_real` = `A lion in the jungle is sleeping <end>`\n",
    "\n",
    "The transformer is an auto-regressive model: it makes predictions one word at a time, and uses its output so far to decide what word to predict next.\n",
    "\n",
    "During training, this example uses teacher-forcing\n",
    "\n",
    "(as in the [text generation tutorial](./text_generation.ipynb)).\n",
    "\n",
    "Teacher forcing is passing the true output to the next time step regardless of what the model predicts at the current time step.\n",
    "\n",
    "As the transformer predicts each word, **self-attention** allows it to look at the previous words in the input sequence to better predict the next word.\n",
    "\n",
    "To prevent the model from peaking at the expected output, the model uses a look-ahead mask."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6edc3f",
   "metadata": {
    "id": "1b6edc3f"
   },
   "source": [
    "This is our training step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "97477592",
   "metadata": {
    "id": "97477592"
   },
   "outputs": [],
   "source": [
    "# The @tf.function trace-compiles train_step into a TF graph for faster\n",
    "# execution. The function specializes to the precise shape of the argument\n",
    "# tensors. To avoid re-tracing due to the variable sequence lengths or variable\n",
    "# batch sizes (the last batch is smaller), use input_signature to specify\n",
    "# more generic shapes.\n",
    "\n",
    "# for bigger corpuses\n",
    "#train_step_signature = [\n",
    "#    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "#    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "#]\n",
    "\n",
    "# for our corpus\n",
    "train_step_signature = [\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int32),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int32),\n",
    "]\n",
    "\n",
    "@tf.function(input_signature=train_step_signature)\n",
    "def train_step(inp, tar):\n",
    "    tar_inp = tar[:, :-1]\n",
    "    tar_real = tar[:, 1:]\n",
    "\n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, _ = transformer(inp, tar_inp,\n",
    "                                     True,\n",
    "                                     enc_padding_mask,\n",
    "                                     combined_mask,\n",
    "                                     dec_padding_mask)\n",
    "        loss = loss_function(tar_real, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, transformer.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(tar_real, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cfc2d0",
   "metadata": {
    "id": "06cfc2d0"
   },
   "source": [
    "And this is our training loop:\n",
    "\n",
    "### Before you run this, run the cells below, which define the translation routine\n",
    "We'll be running translations inline as we're training the transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e8d30217",
   "metadata": {
    "id": "e8d30217"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "22f55ab8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "22f55ab8",
    "outputId": "7ba1f79e-c827-4e85-f400-2585a93b8a18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 0.1645 Accuracy 0.2835\n",
      "Epoch 1 Batch 50 Loss 0.1886 Accuracy 0.2939\n",
      "Epoch 1 Batch 100 Loss 0.1983 Accuracy 0.2956\n",
      "Epoch 1 Loss 0.2037 Accuracy 0.2964\n",
      "Time taken for 1 epoch: 4.30705189704895 secs\n",
      "\n",
      "<start> i like my job very much <end>\n",
      "[[1, 5, 35, 13, 167, 55, 107, 2]]\n",
      "[1, 1, 5, 35, 13, 167, 55, 107, 2, 2]\n",
      "[  1  12  84  47  21 110   3]\n",
      "Input: <start> i like my job very much <end>\n",
      "Predicted translation: ['<start> मुझे अपना काम बहुत पसंद है']\n",
      "Epoch 2 Batch 0 Loss 0.1776 Accuracy 0.2902\n",
      "Epoch 2 Batch 50 Loss 0.1904 Accuracy 0.3003\n",
      "Epoch 2 Batch 100 Loss 0.2012 Accuracy 0.2965\n",
      "Epoch 2 Loss 0.2089 Accuracy 0.2955\n",
      "Time taken for 1 epoch: 5.4503607749938965 secs\n",
      "\n",
      "<start> there is a strange man at the door <end>\n",
      "[[1, 43, 8, 7, 543, 86, 29, 3, 164, 2]]\n",
      "[1, 1, 43, 8, 7, 543, 86, 29, 3, 164, 2, 2]\n",
      "[  1 289  18  54 388 514 300   3]\n",
      "Input: <start> there is a strange man at the door <end>\n",
      "Predicted translation: ['<start> दरवाज़े पर कोई अजीब सा इनसान है']\n",
      "Epoch 3 Batch 0 Loss 0.2112 Accuracy 0.3616\n",
      "Epoch 3 Batch 50 Loss 0.1846 Accuracy 0.2975\n",
      "Epoch 3 Batch 100 Loss 0.2018 Accuracy 0.2971\n",
      "Epoch 3 Loss 0.2083 Accuracy 0.2963\n",
      "Time taken for 1 epoch: 4.294848442077637 secs\n",
      "\n",
      "<start> my birthday is one month from today <end>\n",
      "[[1, 13, 256, 8, 72, 174, 48, 110, 2]]\n",
      "[1, 1, 13, 256, 8, 72, 174, 48, 110, 2, 2]\n",
      "[  1  80 296  88   7  22 205   4   3]\n",
      "Input: <start> my birthday is one month from today <end>\n",
      "Predicted translation: ['<start> मेरा जन्मदिन आज से एक महीने में है']\n",
      "Epoch 4 Batch 0 Loss 0.1589 Accuracy 0.3237\n",
      "Epoch 4 Batch 50 Loss 0.1644 Accuracy 0.2969\n",
      "Epoch 4 Batch 100 Loss 0.1808 Accuracy 0.2973\n",
      "Epoch 4 Loss 0.1847 Accuracy 0.2980\n",
      "Time taken for 1 epoch: 5.582632541656494 secs\n",
      "\n",
      "<start> i had a strange dream last night <end>\n",
      "[[1, 5, 49, 7, 543, 532, 100, 207, 2]]\n",
      "[1, 1, 5, 49, 7, 543, 532, 100, 207, 2, 2]\n",
      "[  1  12  46 161  22  21 388 579 209]\n",
      "Input: <start> i had a strange dream last night <end>\n",
      "Predicted translation: ['<start> मुझे कल रात एक बहुत अजीब सपना आया']\n",
      "Epoch 5 Batch 0 Loss 0.0781 Accuracy 0.2969\n",
      "Epoch 5 Batch 50 Loss 0.1516 Accuracy 0.3018\n",
      "Epoch 5 Batch 100 Loss 0.1769 Accuracy 0.2990\n",
      "Saving checkpoint for epoch 5 at /content/drive/MyDrive/training_checkpoints/transformer/ckpt-12\n",
      "Epoch 5 Loss 0.1820 Accuracy 0.2986\n",
      "Time taken for 1 epoch: 4.892346382141113 secs\n",
      "\n",
      "<start> her way of talking got on my nerves <end>\n",
      "[[1, 33, 163, 10, 282, 129, 25, 13, 978, 2]]\n",
      "[1, 1, 33, 163, 10, 282, 129, 25, 13, 978, 2, 2]\n",
      "[   1   49 2035   18  105  717   17 2036    3    6   21 2037   16   30\n",
      "    3]\n",
      "Input: <start> her way of talking got on my nerves <end>\n",
      "Predicted translation: ['<start> उसकी गाल पर जो चोट का निशान है वह बहुत हल्का हो गया है']\n",
      "Epoch 6 Batch 0 Loss 0.1720 Accuracy 0.3304\n",
      "Epoch 6 Batch 50 Loss 0.1583 Accuracy 0.3022\n",
      "Epoch 6 Batch 100 Loss 0.1729 Accuracy 0.2975\n",
      "Epoch 6 Loss 0.1804 Accuracy 0.2985\n",
      "Time taken for 1 epoch: 5.433449029922485 secs\n",
      "\n",
      "<start> what time did your friend go home <end>\n",
      "[[1, 32, 42, 65, 31, 266, 38, 109, 2]]\n",
      "[1, 1, 32, 42, 65, 31, 266, 38, 109, 2, 2]\n",
      "[  1 278 212 157  71  63 121  30  15]\n",
      "Input: <start> what time did your friend go home <end>\n",
      "Predicted translation: ['<start> तुम्हारा दोस्त कितने बजे घर वापस गया था']\n",
      "Epoch 7 Batch 0 Loss 0.1478 Accuracy 0.3214\n",
      "Epoch 7 Batch 50 Loss 0.1592 Accuracy 0.3013\n",
      "Epoch 7 Batch 100 Loss 0.1771 Accuracy 0.2984\n",
      "Epoch 7 Loss 0.1764 Accuracy 0.2987\n",
      "Time taken for 1 epoch: 4.398572206497192 secs\n",
      "\n",
      "<start> the news caused alarm throughout the village <end>\n",
      "[[1, 3, 291, 1075, 1876, 1877, 3, 388, 2]]\n",
      "[1, 1, 3, 291, 1075, 1876, 1877, 3, 388, 2, 2]\n",
      "[   1 2087  134    9  186  351   82]\n",
      "Input: <start> the news caused alarm throughout the village <end>\n",
      "Predicted translation: ['<start> पौधे बारिश के बिना मर गए']\n",
      "Epoch 8 Batch 0 Loss 0.1028 Accuracy 0.2924\n",
      "Epoch 8 Batch 50 Loss 0.1445 Accuracy 0.3033\n",
      "Epoch 8 Batch 100 Loss 0.1675 Accuracy 0.2995\n",
      "Epoch 8 Loss 0.1681 Accuracy 0.2991\n",
      "Time taken for 1 epoch: 7.5096375942230225 secs\n",
      "\n",
      "<start> the storm destroyed the whole town <end>\n",
      "[[1, 3, 1014, 757, 3, 570, 329, 2]]\n",
      "[1, 1, 3, 1014, 757, 3, 570, 329, 2, 2]\n",
      "[   1 1109   39  411  221   10 1859   26   58]\n",
      "Input: <start> the storm destroyed the whole town <end>\n",
      "Predicted translation: ['<start> तूफ़ान ने पूरे शहर को तबाह कर दिया']\n",
      "Epoch 9 Batch 0 Loss 0.1706 Accuracy 0.3348\n",
      "Epoch 9 Batch 50 Loss 0.1507 Accuracy 0.3027\n",
      "Epoch 9 Batch 100 Loss 0.1626 Accuracy 0.2998\n",
      "Epoch 9 Loss 0.1689 Accuracy 0.2991\n",
      "Time taken for 1 epoch: 4.302968263626099 secs\n",
      "\n",
      "<start> do you believe in fairies <end>\n",
      "[[1, 21, 6, 217, 11, 833, 2]]\n",
      "[1, 1, 21, 6, 217, 11, 833, 2, 2]\n",
      "[  1  14  24  52   4 165 261  16]\n",
      "Input: <start> do you believe in fairies <end>\n",
      "Predicted translation: ['<start> क्या तुम उस में अच्छी लगती हो']\n",
      "Epoch 10 Batch 0 Loss 0.1400 Accuracy 0.3170\n",
      "Epoch 10 Batch 50 Loss 0.1393 Accuracy 0.3069\n",
      "Epoch 10 Batch 100 Loss 0.1608 Accuracy 0.3011\n",
      "Saving checkpoint for epoch 10 at /content/drive/MyDrive/training_checkpoints/transformer/ckpt-13\n",
      "Epoch 10 Loss 0.1656 Accuracy 0.3000\n",
      "Time taken for 1 epoch: 5.295231819152832 secs\n",
      "\n",
      "<start> you can buy whichever you like COMMA but not both <end>\n",
      "[[1, 6, 40, 251, 1887, 6, 35, 12, 76, 30, 179, 2]]\n",
      "[1, 1, 6, 40, 251, 1887, 6, 35, 12, 76, 30, 179, 2, 2]\n",
      "[   1   24 2116   33   37 2117   33   37    5   26   45]\n",
      "Input: <start> you can buy whichever you like COMMA but not both <end>\n",
      "Predicted translation: ['<start> तुम चित भी मेरी पट भी मेरी नहीं कर सकते']\n",
      "Epoch 11 Batch 0 Loss 0.2687 Accuracy 0.3080\n",
      "Epoch 11 Batch 50 Loss 0.1313 Accuracy 0.3010\n",
      "Epoch 11 Batch 100 Loss 0.1469 Accuracy 0.3008\n",
      "Epoch 11 Loss 0.1548 Accuracy 0.3007\n",
      "Time taken for 1 epoch: 4.70469069480896 secs\n",
      "\n",
      "<start> he was buried in this graveyard <end>\n",
      "[[1, 9, 20, 721, 11, 17, 948, 2]]\n",
      "[1, 1, 9, 20, 721, 11, 17, 948, 2, 2]\n",
      "[   1   75   31  771    4 1037   50   30   15]\n",
      "Input: <start> he was buried in this graveyard <end>\n",
      "Predicted translation: ['<start> उसको इस कब्रिस्तान में बरी किया गया था']\n",
      "Epoch 12 Batch 0 Loss 0.1776 Accuracy 0.2790\n",
      "Epoch 12 Batch 50 Loss 0.1303 Accuracy 0.3020\n",
      "Epoch 12 Batch 100 Loss 0.1386 Accuracy 0.3012\n",
      "Epoch 12 Loss 0.1437 Accuracy 0.3009\n",
      "Time taken for 1 epoch: 4.440275192260742 secs\n",
      "\n",
      "<start> she poured coffee into the cups on the table <end>\n",
      "[[1, 16, 1867, 244, 139, 3, 827, 25, 3, 727, 2]]\n",
      "[1, 1, 16, 1867, 244, 139, 3, 827, 25, 3, 727, 2, 2]\n",
      "[   1   19  292   18 2227  111 2228    4  282 2229]\n",
      "Input: <start> she poured coffee into the cups on the table <end>\n",
      "Predicted translation: ['<start> उसने मेज़ पर रखे हुए कपों में कॉफ़ी डाली']\n",
      "Epoch 13 Batch 0 Loss 0.1801 Accuracy 0.3103\n",
      "Epoch 13 Batch 50 Loss 0.1489 Accuracy 0.2967\n",
      "Epoch 13 Batch 100 Loss 0.1540 Accuracy 0.2993\n",
      "Epoch 13 Loss 0.1545 Accuracy 0.3000\n",
      "Time taken for 1 epoch: 4.896226406097412 secs\n",
      "\n",
      "<start> read as many books as possible <end>\n",
      "[[1, 197, 47, 103, 212, 47, 337, 2]]\n",
      "[1, 1, 197, 47, 103, 212, 47, 337, 2, 2]\n",
      "[   1  495  274  276   45   16 1021]\n",
      "Input: <start> read as many books as possible <end>\n",
      "Predicted translation: ['<start> जितनी किताबें पढ़ सकते हो पढ़ो']\n",
      "Epoch 14 Batch 0 Loss 0.0891 Accuracy 0.3147\n",
      "Epoch 14 Batch 50 Loss 0.1259 Accuracy 0.3050\n",
      "Epoch 14 Batch 100 Loss 0.1491 Accuracy 0.3015\n",
      "Epoch 14 Loss 0.1517 Accuracy 0.3006\n",
      "Time taken for 1 epoch: 4.235716819763184 secs\n",
      "\n",
      "<start> if the coffee is too strong COMMA add some more water <end>\n",
      "[[1, 61, 3, 244, 8, 111, 598, 12, 649, 134, 101, 160, 2]]\n",
      "[1, 1, 61, 3, 244, 8, 111, 598, 12, 649, 134, 101, 160, 2, 2]\n",
      "[   1  117  282   97 2324    3   40  171   32  182 2325]\n",
      "Input: <start> if the coffee is too strong COMMA add some more water <end>\n",
      "Predicted translation: ['<start> अगर कॉफ़ी ज़्यादा कड़वी है तो थोड़ा और पानी डाललो']\n",
      "Epoch 15 Batch 0 Loss 0.0618 Accuracy 0.2946\n",
      "Epoch 15 Batch 50 Loss 0.1203 Accuracy 0.3052\n",
      "Epoch 15 Batch 100 Loss 0.1344 Accuracy 0.3029\n",
      "Saving checkpoint for epoch 15 at /content/drive/MyDrive/training_checkpoints/transformer/ckpt-14\n",
      "Epoch 15 Loss 0.1410 Accuracy 0.3014\n",
      "Time taken for 1 epoch: 5.920160293579102 secs\n",
      "\n",
      "<start> bring your sister next time <end>\n",
      "[[1, 647, 31, 210, 144, 42, 2]]\n",
      "[1, 1, 647, 31, 210, 144, 42, 2, 2]\n",
      "[   1  719  124   44  246   10   33   64 1458]\n",
      "Input: <start> bring your sister next time <end>\n",
      "Predicted translation: ['<start> अगली बार अपनी बहन को भी साथ लाना']\n",
      "Epoch 16 Batch 0 Loss 0.1395 Accuracy 0.3013\n",
      "Epoch 16 Batch 50 Loss 0.1193 Accuracy 0.3058\n",
      "Epoch 16 Batch 100 Loss 0.1393 Accuracy 0.3013\n",
      "Epoch 16 Loss 0.1385 Accuracy 0.3019\n",
      "Time taken for 1 epoch: 4.30185866355896 secs\n",
      "\n",
      "<start> we tried it again COMMA but couldnt do it <end>\n",
      "[[1, 27, 192, 15, 156, 12, 76, 188, 21, 15, 2]]\n",
      "[1, 1, 27, 192, 15, 156, 12, 76, 188, 21, 15, 2, 2]\n",
      "[   1  148  222   38   13 2006   13   28   18    5   26 1132]\n",
      "Input: <start> we tried it again COMMA but couldnt do it <end>\n",
      "Predicted translation: ['<start> हमने फिरसे करने की कोशीश की comma पर नहीं कर पाए']\n",
      "Epoch 17 Batch 0 Loss 0.0821 Accuracy 0.3080\n",
      "Epoch 17 Batch 50 Loss 0.1213 Accuracy 0.3022\n",
      "Epoch 17 Batch 100 Loss 0.1321 Accuracy 0.3029\n",
      "Epoch 17 Loss 0.1352 Accuracy 0.3019\n",
      "Time taken for 1 epoch: 5.548585891723633 secs\n",
      "\n",
      "<start> he must be over sixty <end>\n",
      "[[1, 9, 116, 37, 800, 1146, 2]]\n",
      "[1, 1, 9, 116, 37, 800, 1146, 2, 2]\n",
      "[  1   6 140 318  86 130   5 287]\n",
      "Input: <start> he must be over sixty <end>\n",
      "Predicted translation: ['<start> वह वहाँ अकेले जाने क्यों नहीं आई']\n",
      "Epoch 18 Batch 0 Loss 0.0560 Accuracy 0.2746\n",
      "Epoch 18 Batch 50 Loss 0.1251 Accuracy 0.3013\n",
      "Epoch 18 Batch 100 Loss 0.1300 Accuracy 0.3014\n",
      "Epoch 18 Loss 0.1309 Accuracy 0.3025\n",
      "Time taken for 1 epoch: 4.292610168457031 secs\n",
      "\n",
      "<start> my father is very nice <end>\n",
      "[[1, 13, 67, 8, 55, 405, 2]]\n",
      "[1, 1, 13, 67, 8, 55, 405, 2, 2]\n",
      "[  1  27 155  21 283  11]\n",
      "Input: <start> my father is very nice <end>\n",
      "Predicted translation: ['<start> मेरे पापा बहुत अच्छे हैं']\n",
      "Epoch 19 Batch 0 Loss 0.1204 Accuracy 0.2835\n",
      "Epoch 19 Batch 50 Loss 0.1209 Accuracy 0.3055\n",
      "Epoch 19 Batch 100 Loss 0.1255 Accuracy 0.3032\n",
      "Epoch 19 Loss 0.1297 Accuracy 0.3028\n",
      "Time taken for 1 epoch: 5.368349552154541 secs\n",
      "\n",
      "<start> ill call you back later <end>\n",
      "[[1, 88, 142, 6, 89, 505, 2]]\n",
      "[1, 1, 88, 142, 6, 89, 505, 2, 2]\n",
      "[  1   8 132 181 114 230 170 548]\n",
      "Input: <start> ill call you back later <end>\n",
      "Predicted translation: ['<start> मैं आपको थोड़ी देर बाद फ़ोन करूँगा']\n",
      "Epoch 20 Batch 0 Loss 0.1509 Accuracy 0.3036\n",
      "Epoch 20 Batch 50 Loss 0.1162 Accuracy 0.3048\n",
      "Epoch 20 Batch 100 Loss 0.1264 Accuracy 0.3040\n",
      "Saving checkpoint for epoch 20 at /content/drive/MyDrive/training_checkpoints/transformer/ckpt-15\n",
      "Epoch 20 Loss 0.1297 Accuracy 0.3030\n",
      "Time taken for 1 epoch: 4.741009712219238 secs\n",
      "\n",
      "<start> how long will you stay here <end>\n",
      "[[1, 46, 78, 26, 6, 257, 63, 2]]\n",
      "[1, 1, 46, 78, 26, 6, 257, 63, 2, 2]\n",
      "[  1  90  78 157 116 942]\n",
      "Input: <start> how long will you stay here <end>\n",
      "Predicted translation: ['<start> आप यहाँ कितने दिन रहेंगे']\n",
      "Epoch 21 Batch 0 Loss 0.1171 Accuracy 0.3058\n",
      "Epoch 21 Batch 50 Loss 0.1200 Accuracy 0.3058\n",
      "Epoch 21 Batch 100 Loss 0.1265 Accuracy 0.3022\n",
      "Epoch 21 Loss 0.1286 Accuracy 0.3025\n",
      "Time taken for 1 epoch: 5.192597389221191 secs\n",
      "\n",
      "<start> i advise you to stop smoking <end>\n",
      "[[1, 5, 684, 6, 4, 307, 283, 2]]\n",
      "[1, 1, 5, 684, 6, 4, 307, 283, 2, 2]\n",
      "[  1  27 389   7  74 262 361 150 235 340]\n",
      "Input: <start> i advise you to stop smoking <end>\n",
      "Predicted translation: ['<start> मेरे ख़याल से तुम्हे सिगरेट पीना छोड़ देना चहिए']\n",
      "Epoch 22 Batch 0 Loss 0.0845 Accuracy 0.3393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-109-dfd3264d2dd7>:2: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  fig = plt.figure(figsize=(16, 8))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 Batch 50 Loss 0.1057 Accuracy 0.3045\n",
      "Epoch 22 Batch 100 Loss 0.1138 Accuracy 0.3041\n",
      "Epoch 22 Loss 0.1174 Accuracy 0.3036\n",
      "Time taken for 1 epoch: 4.378880262374878 secs\n",
      "\n",
      "<start> my uncle is an amateur cricket player <end>\n",
      "[[1, 13, 577, 8, 64, 578, 579, 580, 2]]\n",
      "[1, 1, 13, 577, 8, 64, 578, 579, 580, 2, 2]\n",
      "[   1   27 1982  635    9  636  637   11]\n",
      "Input: <start> my uncle is an amateur cricket player <end>\n",
      "Predicted translation: ['<start> मेरे चाचा क्रिकेट के शौकिया खिलाड़ी हैं']\n",
      "Epoch 23 Batch 0 Loss 0.0542 Accuracy 0.2879\n",
      "Epoch 23 Batch 50 Loss 0.1105 Accuracy 0.3120\n",
      "Epoch 23 Batch 100 Loss 0.1230 Accuracy 0.3049\n",
      "Epoch 23 Loss 0.1248 Accuracy 0.3032\n",
      "Time taken for 1 epoch: 5.270899534225464 secs\n",
      "\n",
      "<start> few people will admit their faults <end>\n",
      "[[1, 157, 119, 26, 1529, 177, 1530, 2]]\n",
      "[1, 1, 157, 119, 26, 1529, 177, 1530, 2, 2]\n",
      "[   1   70  153 2158   10 2159  185   11]\n",
      "Input: <start> few people will admit their faults <end>\n",
      "Predicted translation: ['<start> कुछ लोग संविधान को सुधारना चाहते हैं']\n",
      "Epoch 24 Batch 0 Loss 0.0842 Accuracy 0.3460\n",
      "Epoch 24 Batch 50 Loss 0.1038 Accuracy 0.3060\n",
      "Epoch 24 Batch 100 Loss 0.1125 Accuracy 0.3043\n",
      "Epoch 24 Loss 0.1146 Accuracy 0.3043\n",
      "Time taken for 1 epoch: 4.189028024673462 secs\n",
      "\n",
      "<start> he doesnt have long to live <end>\n",
      "[[1, 9, 273, 14, 78, 4, 99, 2]]\n",
      "[1, 1, 9, 273, 14, 78, 4, 99, 2, 2]\n",
      "[   1   48   42 1518    9   23   97   57    5    3]\n",
      "Input: <start> he doesnt have long to live <end>\n",
      "Predicted translation: ['<start> उसके पास जीने के लिए ज़्यादा समय नहीं है']\n",
      "Epoch 25 Batch 0 Loss 0.0558 Accuracy 0.3259\n",
      "Epoch 25 Batch 50 Loss 0.0974 Accuracy 0.3072\n",
      "Epoch 25 Batch 100 Loss 0.1058 Accuracy 0.3048\n",
      "Saving checkpoint for epoch 25 at /content/drive/MyDrive/training_checkpoints/transformer/ckpt-16\n",
      "Epoch 25 Loss 0.1078 Accuracy 0.3045\n",
      "Time taken for 1 epoch: 5.956194639205933 secs\n",
      "\n",
      "<start> we painted the door green <end>\n",
      "[[1, 27, 1238, 3, 164, 1239, 2]]\n",
      "[1, 1, 27, 1238, 3, 164, 1239, 2, 2]\n",
      "[   1  148  289   10 1410  439    7 1411   58]\n",
      "Input: <start> we painted the door green <end>\n",
      "Predicted translation: ['<start> हमने दरवाज़े को हरे रंग से पोत दिया']\n",
      "Epoch 26 Batch 0 Loss 0.1220 Accuracy 0.3326\n",
      "Epoch 26 Batch 50 Loss 0.1004 Accuracy 0.3037\n",
      "Epoch 26 Batch 100 Loss 0.1100 Accuracy 0.3044\n",
      "Epoch 26 Loss 0.1095 Accuracy 0.3041\n",
      "Time taken for 1 epoch: 4.178445816040039 secs\n",
      "\n",
      "<start> did you do your homework <end>\n",
      "[[1, 65, 6, 21, 31, 413, 2]]\n",
      "[1, 1, 65, 6, 21, 31, 413, 2, 2]\n",
      "[  1 142  84 460  26 118  14]\n",
      "Input: <start> did you do your homework <end>\n",
      "Predicted translation: ['<start> तुमने अपना होमवर्क कर लिया क्या']\n",
      "Epoch 27 Batch 0 Loss 0.1292 Accuracy 0.3103\n",
      "Epoch 27 Batch 50 Loss 0.0965 Accuracy 0.3021\n",
      "Epoch 27 Batch 100 Loss 0.1143 Accuracy 0.3025\n",
      "Epoch 27 Loss 0.1180 Accuracy 0.3037\n",
      "Time taken for 1 epoch: 5.600414037704468 secs\n",
      "\n",
      "<start> i bought two dozen pencils <end>\n",
      "[[1, 5, 248, 75, 812, 854, 2]]\n",
      "[1, 1, 5, 248, 75, 812, 854, 2, 2]\n",
      "[   1   34   72  881 1422  935]\n",
      "Input: <start> i bought two dozen pencils <end>\n",
      "Predicted translation: ['<start> मैंने दो दर्जन पेनसिलें खरीदीं']\n",
      "Epoch 28 Batch 0 Loss 0.1434 Accuracy 0.3326\n",
      "Epoch 28 Batch 50 Loss 0.0892 Accuracy 0.3086\n",
      "Epoch 28 Batch 100 Loss 0.0999 Accuracy 0.3046\n",
      "Epoch 28 Loss 0.1067 Accuracy 0.3050\n",
      "Time taken for 1 epoch: 4.299047946929932 secs\n",
      "\n",
      "<start> take back what you said about me being stingy <end>\n",
      "[[1, 66, 89, 32, 6, 190, 71, 19, 460, 961, 2]]\n",
      "[1, 1, 66, 89, 32, 6, 190, 71, 19, 460, 961, 2, 2]\n",
      "[   1  105  142   27 1054  151    9  120    4  146   15   28   52   60\n",
      "   10  121  832]\n",
      "Input: <start> take back what you said about me being stingy <end>\n",
      "Predicted translation: ['<start> जो तुमने मेरे कंजूस होने के बारे में कहा था comma उस बात को वापस लो']\n",
      "Epoch 29 Batch 0 Loss 0.0833 Accuracy 0.2924\n",
      "Epoch 29 Batch 50 Loss 0.0925 Accuracy 0.3048\n",
      "Epoch 29 Batch 100 Loss 0.1015 Accuracy 0.3053\n",
      "Epoch 29 Loss 0.1030 Accuracy 0.3048\n",
      "Time taken for 1 epoch: 5.51594614982605 secs\n",
      "\n",
      "<start> we rested for a while <end>\n",
      "[[1, 27, 1156, 18, 7, 243, 2]]\n",
      "[1, 1, 27, 1156, 18, 7, 243, 2, 2]\n",
      "[  1 148 181 114 337  50]\n",
      "Input: <start> we rested for a while <end>\n",
      "Predicted translation: ['<start> हमने थोड़ी देर आराम किया']\n",
      "Epoch 30 Batch 0 Loss 0.1787 Accuracy 0.3058\n",
      "Epoch 30 Batch 50 Loss 0.0918 Accuracy 0.3043\n",
      "Epoch 30 Batch 100 Loss 0.1031 Accuracy 0.3046\n",
      "Saving checkpoint for epoch 30 at /content/drive/MyDrive/training_checkpoints/transformer/ckpt-17\n",
      "Epoch 30 Loss 0.1082 Accuracy 0.3043\n",
      "Time taken for 1 epoch: 4.956484317779541 secs\n",
      "\n",
      "<start> youve got nothing to complain of <end>\n",
      "[[1, 495, 129, 122, 4, 1521, 10, 2]]\n",
      "[1, 1, 495, 129, 122, 4, 1521, 10, 2, 2]\n",
      "[   1   53   42 1090   38    9   23   10   33  208    5    3]\n",
      "Input: <start> youve got nothing to complain of <end>\n",
      "Predicted translation: ['<start> तुम्हारे पास शिकायत करने के लिए को भी वजह नहीं है']\n",
      "Epoch 31 Batch 0 Loss 0.0572 Accuracy 0.3058\n",
      "Epoch 31 Batch 50 Loss 0.0937 Accuracy 0.3064\n",
      "Epoch 31 Batch 100 Loss 0.0955 Accuracy 0.3058\n",
      "Epoch 31 Loss 0.1000 Accuracy 0.3049\n",
      "Time taken for 1 epoch: 5.570476055145264 secs\n",
      "\n",
      "<start> he is used to hard work <end>\n",
      "[[1, 9, 8, 247, 4, 180, 92, 2]]\n",
      "[1, 1, 9, 8, 247, 4, 180, 92, 2, 2]\n",
      "[   1    6   35  338 2494  918    3]\n",
      "Input: <start> he is used to hard work <end>\n",
      "Predicted translation: ['<start> वह अपने बाल कटवाना चाह्ती है']\n",
      "Epoch 32 Batch 0 Loss 0.0939 Accuracy 0.3237\n",
      "Epoch 32 Batch 50 Loss 0.0915 Accuracy 0.3066\n",
      "Epoch 32 Batch 100 Loss 0.0993 Accuracy 0.3042\n",
      "Epoch 32 Loss 0.1058 Accuracy 0.3045\n",
      "Time taken for 1 epoch: 4.348913908004761 secs\n",
      "\n",
      "<start> it doesnt matter whether he agrees or not <end>\n",
      "[[1, 15, 273, 468, 344, 9, 1799, 141, 30, 2]]\n",
      "[1, 1, 15, 273, 468, 344, 9, 1799, 141, 30, 2, 2]\n",
      "[   1    6 1200  158   79 1200   81   70  295    5  316]\n",
      "Input: <start> it doesnt matter whether he agrees or not <end>\n",
      "Predicted translation: ['<start> वह माने या न माने उससे कुछ फ़र्क नहीं पड़ता']\n",
      "Epoch 33 Batch 0 Loss 0.0882 Accuracy 0.3214\n",
      "Epoch 33 Batch 50 Loss 0.0912 Accuracy 0.3081\n",
      "Epoch 33 Batch 100 Loss 0.1012 Accuracy 0.3060\n",
      "Epoch 33 Loss 0.1018 Accuracy 0.3052\n",
      "Time taken for 1 epoch: 6.134389638900757 secs\n",
      "\n",
      "<start> i tried to give her some money COMMA but she wouldnt take any <end>\n",
      "[[1, 5, 192, 4, 153, 33, 134, 82, 12, 76, 16, 576, 66, 128, 2]]\n",
      "[1, 1, 5, 192, 4, 153, 33, 134, 82, 12, 76, 16, 576, 66, 128, 2, 2]\n",
      "[  1  34  75 101 366  13 195 138  18  19 690  26  58]\n",
      "Input: <start> i tried to give her some money COMMA but she wouldnt take any <end>\n",
      "Predicted translation: ['<start> मैंने उसको पैसे देने की कोशिश करी पर उसने इनकार कर दिया']\n",
      "Epoch 34 Batch 0 Loss 0.1190 Accuracy 0.2991\n",
      "Epoch 34 Batch 50 Loss 0.0856 Accuracy 0.3068\n",
      "Epoch 34 Batch 100 Loss 0.0981 Accuracy 0.3050\n",
      "Epoch 34 Loss 0.1002 Accuracy 0.3050\n",
      "Time taken for 1 epoch: 4.366365194320679 secs\n",
      "\n",
      "<start> can we have a talk <end>\n",
      "[[1, 40, 27, 14, 7, 261, 2]]\n",
      "[1, 1, 40, 27, 14, 7, 261, 2, 2]\n",
      "[  1 242 305  28  18   8  54 711  83  20]\n",
      "Input: <start> can we have a talk <end>\n",
      "Predicted translation: ['<start> माफ़ कीजिएगा comma पर मैं कोई बैठा हुआ हूँ']\n",
      "Epoch 35 Batch 0 Loss 0.0638 Accuracy 0.3348\n",
      "Epoch 35 Batch 50 Loss 0.0838 Accuracy 0.3083\n",
      "Epoch 35 Batch 100 Loss 0.0924 Accuracy 0.3069\n",
      "Saving checkpoint for epoch 35 at /content/drive/MyDrive/training_checkpoints/transformer/ckpt-18\n",
      "Epoch 35 Loss 0.0962 Accuracy 0.3058\n",
      "Time taken for 1 epoch: 5.39601469039917 secs\n",
      "\n",
      "<start> give up smoking if you want to live long <end>\n",
      "[[1, 153, 45, 283, 61, 6, 59, 4, 99, 78, 2]]\n",
      "[1, 1, 153, 45, 283, 61, 6, 59, 4, 99, 78, 2, 2]\n",
      "[   1  117  576  456 1094  185   16   40  262  361  150   72]\n",
      "Input: <start> give up smoking if you want to live long <end>\n",
      "Predicted translation: ['<start> अगर लम्बी ज़िन्दगी जीना चाहते हो तो सिगरेट पीना छोड़ दो']\n",
      "Epoch 36 Batch 0 Loss 0.0459 Accuracy 0.2902\n",
      "Epoch 36 Batch 50 Loss 0.0793 Accuracy 0.3064\n",
      "Epoch 36 Batch 100 Loss 0.0925 Accuracy 0.3052\n",
      "Epoch 36 Loss 0.0927 Accuracy 0.3053\n",
      "Time taken for 1 epoch: 4.809545516967773 secs\n",
      "\n",
      "<start> i ran away in a hurry <end>\n",
      "[[1, 5, 267, 151, 11, 7, 352, 2]]\n",
      "[1, 1, 5, 267, 151, 11, 7, 352, 2, 2]\n",
      "[   1    8 1272    4  856   30]\n",
      "Input: <start> i ran away in a hurry <end>\n",
      "Predicted translation: ['<start> मैं हड़बड़ी में दौड़ गया']\n",
      "Epoch 37 Batch 0 Loss 0.0669 Accuracy 0.3214\n",
      "Epoch 37 Batch 50 Loss 0.0779 Accuracy 0.3048\n",
      "Epoch 37 Batch 100 Loss 0.0912 Accuracy 0.3064\n",
      "Epoch 37 Loss 0.0967 Accuracy 0.3057\n",
      "Time taken for 1 epoch: 4.4531636238098145 secs\n",
      "\n",
      "<start> who is the author of the novel <end>\n",
      "[[1, 126, 8, 3, 942, 10, 3, 503, 2]]\n",
      "[1, 1, 126, 8, 3, 942, 10, 3, 503, 2, 2]\n",
      "[   1   31  545   17 1033  390    3]\n",
      "Input: <start> who is the author of the novel <end>\n",
      "Predicted translation: ['<start> इस उपन्यास का लेखक कौन है']\n",
      "Epoch 38 Batch 0 Loss 0.2461 Accuracy 0.2656\n",
      "Epoch 38 Batch 50 Loss 0.0778 Accuracy 0.3079\n",
      "Epoch 38 Batch 100 Loss 0.0822 Accuracy 0.3077\n",
      "Epoch 38 Loss 0.0875 Accuracy 0.3064\n",
      "Time taken for 1 epoch: 5.107598304748535 secs\n",
      "\n",
      "<start> she cooked us a wonderful meal <end>\n",
      "[[1, 16, 615, 94, 7, 931, 932, 2]]\n",
      "[1, 1, 16, 615, 94, 7, 931, 932, 2, 2]\n",
      "[   1   19  145   23   21   41 1025 1026  288   50]\n",
      "Input: <start> she cooked us a wonderful meal <end>\n",
      "Predicted translation: ['<start> उसने हमारे लिए बहुत ही शानदार भोजन तैयार किया']\n",
      "Epoch 39 Batch 0 Loss 0.0771 Accuracy 0.3125\n",
      "Epoch 39 Batch 50 Loss 0.0772 Accuracy 0.3057\n",
      "Epoch 39 Batch 100 Loss 0.0890 Accuracy 0.3059\n",
      "Epoch 39 Loss 0.0916 Accuracy 0.3060\n",
      "Time taken for 1 epoch: 4.551391363143921 secs\n",
      "\n",
      "<start> i spent hours looking for the key that i had dropped <end>\n",
      "[[1, 5, 787, 286, 252, 18, 3, 628, 23, 5, 49, 1997, 2]]\n",
      "[1, 1, 5, 787, 286, 252, 18, 3, 628, 23, 5, 49, 1997, 2, 2]\n",
      "[  1  12  22 161  10 136 219   9 230  35 216  10  48 460   9  64  98  38\n",
      "  13 286   3]\n",
      "Input: <start> i spent hours looking for the key that i had dropped <end>\n",
      "Predicted translation: ['<start> मुझे एक रात को खाना खाने के बाद अपने भाई को उसके होमवर्क के साथ मदद करने की आदत है']\n",
      "Epoch 40 Batch 0 Loss 0.0536 Accuracy 0.2746\n",
      "Epoch 40 Batch 50 Loss 0.0818 Accuracy 0.3100\n",
      "Epoch 40 Batch 100 Loss 0.0860 Accuracy 0.3071\n",
      "Saving checkpoint for epoch 40 at /content/drive/MyDrive/training_checkpoints/transformer/ckpt-19\n",
      "Epoch 40 Loss 0.0904 Accuracy 0.3061\n",
      "Time taken for 1 epoch: 6.110656976699829 secs\n",
      "\n",
      "<start> they will fall in love with each other <end>\n",
      "[[1, 51, 26, 1050, 11, 498, 34, 433, 231, 2]]\n",
      "[1, 1, 51, 26, 1050, 11, 498, 34, 433, 231, 2, 2]\n",
      "[  1 347 375   7 534  16 198]\n",
      "Input: <start> they will fall in love with each other <end>\n",
      "Predicted translation: ['<start> उन्हें एकदूसरे से प्यार हो जाएगा']\n",
      "Epoch 41 Batch 0 Loss 0.0772 Accuracy 0.3058\n",
      "Epoch 41 Batch 50 Loss 0.0752 Accuracy 0.3069\n",
      "Epoch 41 Batch 100 Loss 0.0910 Accuracy 0.3051\n",
      "Epoch 41 Loss 0.0911 Accuracy 0.3060\n",
      "Time taken for 1 epoch: 4.370010137557983 secs\n",
      "\n",
      "<start> without a dictionary COMMA it would be hard to study english <end>\n",
      "[[1, 172, 7, 728, 12, 15, 74, 37, 180, 4, 323, 93, 2]]\n",
      "[1, 1, 172, 7, 728, 12, 15, 74, 37, 180, 4, 323, 93, 2, 2]\n",
      "[   1 1148 2435    9  186  115   13  499   56   21  196  100]\n",
      "Input: <start> without a dictionary COMMA it would be hard to study english <end>\n",
      "Predicted translation: ['<start> शब्दकोश डिक्शनरी के बिना अंग्रेज़ी की पढ़ाई करना बहुत मुश्किल होगा']\n",
      "Epoch 42 Batch 0 Loss 0.0942 Accuracy 0.3125\n",
      "Epoch 42 Batch 50 Loss 0.0724 Accuracy 0.3102\n",
      "Epoch 42 Batch 100 Loss 0.0816 Accuracy 0.3073\n",
      "Epoch 42 Loss 0.0844 Accuracy 0.3069\n",
      "Time taken for 1 epoch: 5.445777893066406 secs\n",
      "\n",
      "<start> you should make use of this chance <end>\n",
      "[[1, 6, 90, 112, 148, 10, 17, 760, 2]]\n",
      "[1, 1, 6, 90, 112, 148, 10, 17, 760, 2, 2]\n",
      "[   1   74   31  805   17  265 1870   62]\n",
      "Input: <start> you should make use of this chance <end>\n",
      "Predicted translation: ['<start> तुम्हे इस मौके का फ़ायदा उठाना चाहिए']\n",
      "Epoch 43 Batch 0 Loss 0.0704 Accuracy 0.3013\n",
      "Epoch 43 Batch 50 Loss 0.0749 Accuracy 0.3067\n",
      "Epoch 43 Batch 100 Loss 0.0858 Accuracy 0.3076\n",
      "Epoch 43 Loss 0.0878 Accuracy 0.3064\n",
      "Time taken for 1 epoch: 4.20564866065979 secs\n",
      "\n",
      "<start> i was ill at ease because i didnt speak french <end>\n",
      "[[1, 5, 20, 88, 29, 1936, 155, 5, 105, 102, 325, 2]]\n",
      "[1, 1, 5, 20, 88, 29, 1936, 155, 5, 105, 102, 325, 2, 2]\n",
      "[   1    8  590   15  298   12 2306 1142    5  428   51]\n",
      "Input: <start> i was ill at ease because i didnt speak french <end>\n",
      "Predicted translation: ['<start> मैं परेशान था क्योंकि मुझे फ़्रांसीसी बोलनी नहीं आती थी']\n",
      "Epoch 44 Batch 0 Loss 0.1138 Accuracy 0.2589\n",
      "Epoch 44 Batch 50 Loss 0.0676 Accuracy 0.3040\n",
      "Epoch 44 Batch 100 Loss 0.0809 Accuracy 0.3060\n",
      "Epoch 44 Loss 0.0840 Accuracy 0.3060\n",
      "Time taken for 1 epoch: 5.103885650634766 secs\n",
      "\n",
      "<start> i motioned for her to sit down <end>\n",
      "[[1, 5, 1385, 18, 33, 4, 924, 143, 2]]\n",
      "[1, 1, 5, 1385, 18, 33, 4, 924, 143, 2, 2]\n",
      "[   1   34   81 1009   86   17 1620   50]\n",
      "Input: <start> i motioned for her to sit down <end>\n",
      "Predicted translation: ['<start> मैंने उससे बैठ जाने का इशारा किया']\n",
      "Epoch 45 Batch 0 Loss 0.0888 Accuracy 0.2857\n",
      "Epoch 45 Batch 50 Loss 0.0648 Accuracy 0.3081\n",
      "Epoch 45 Batch 100 Loss 0.0740 Accuracy 0.3075\n",
      "Saving checkpoint for epoch 45 at /content/drive/MyDrive/training_checkpoints/transformer/ckpt-20\n",
      "Epoch 45 Loss 0.0798 Accuracy 0.3072\n",
      "Time taken for 1 epoch: 4.822283983230591 secs\n",
      "\n",
      "<start> the shop carried leather goods <end>\n",
      "[[1, 3, 940, 1403, 1404, 1405, 2]]\n",
      "[1, 1, 3, 940, 1403, 1404, 1405, 2, 2]\n",
      "[   1    6  729 1646    9 1647 1648   51]\n",
      "Input: <start> the shop carried leather goods <end>\n",
      "Predicted translation: ['<start> वह दुकान चमड़े के उत्पाद बेचती थी']\n",
      "Epoch 46 Batch 0 Loss 0.0817 Accuracy 0.3214\n",
      "Epoch 46 Batch 50 Loss 0.0721 Accuracy 0.3076\n",
      "Epoch 46 Batch 100 Loss 0.0832 Accuracy 0.3063\n",
      "Epoch 46 Loss 0.0863 Accuracy 0.3063\n",
      "Time taken for 1 epoch: 5.066129207611084 secs\n",
      "\n",
      "<start> this medicine will do you good <end>\n",
      "[[1, 17, 293, 26, 21, 6, 131, 2]]\n",
      "[1, 1, 17, 293, 26, 21, 6, 131, 2, 2]\n",
      "[   1   29  424  278  449 1031]\n",
      "Input: <start> this medicine will do you good <end>\n",
      "Predicted translation: ['<start> यह दवाई तुम्हारा भला करेगी']\n",
      "Epoch 47 Batch 0 Loss 0.1418 Accuracy 0.3304\n",
      "Epoch 47 Batch 50 Loss 0.0719 Accuracy 0.3086\n",
      "Epoch 47 Batch 100 Loss 0.0775 Accuracy 0.3080\n",
      "Epoch 47 Loss 0.0832 Accuracy 0.3070\n",
      "Time taken for 1 epoch: 4.381994962692261 secs\n",
      "\n",
      "<start> when you leave the room COMMA please make sure you turn off the lights <end>\n",
      "[[1, 53, 6, 169, 3, 106, 12, 80, 112, 335, 6, 162, 115, 3, 770, 2]]\n",
      "[1, 1, 53, 6, 169, 3, 106, 12, 80, 112, 335, 6, 162, 115, 3, 770, 2, 2]\n",
      "[   1  184    7 2502    7   89   28  412  821  173   26 2503]\n",
      "Input: <start> when you leave the room COMMA please make sure you turn off the lights <end>\n",
      "Predicted translation: ['<start> कमरे से निकलने से पहले comma कृपया बत्तियाँ बंद कर दीजिएगा']\n",
      "Epoch 48 Batch 0 Loss 0.0478 Accuracy 0.3504\n",
      "Epoch 48 Batch 50 Loss 0.0598 Accuracy 0.3082\n",
      "Epoch 48 Batch 100 Loss 0.0687 Accuracy 0.3089\n",
      "Epoch 48 Loss 0.0750 Accuracy 0.3078\n",
      "Time taken for 1 epoch: 4.99911093711853 secs\n",
      "\n",
      "<start> can i see your passport <end>\n",
      "[[1, 40, 5, 84, 31, 810, 2]]\n",
      "[1, 1, 40, 5, 84, 31, 810, 2, 2]\n",
      "[  1   8 454 877 228  59  20  14]\n",
      "Input: <start> can i see your passport <end>\n",
      "Predicted translation: ['<start> मैं आपका पासपोर्ट देख सकता हूँ क्या']\n",
      "Epoch 49 Batch 0 Loss 0.0383 Accuracy 0.3036\n",
      "Epoch 49 Batch 50 Loss 0.0673 Accuracy 0.3065\n",
      "Epoch 49 Batch 100 Loss 0.0813 Accuracy 0.3072\n",
      "Epoch 49 Loss 0.0828 Accuracy 0.3065\n",
      "Time taken for 1 epoch: 4.132445573806763 secs\n",
      "\n",
      "<start> sometimes she tried talking to him about india <end>\n",
      "[[1, 1056, 16, 192, 282, 4, 28, 71, 62, 2]]\n",
      "[1, 1, 1056, 16, 192, 282, 4, 28, 71, 62, 2, 2]\n",
      "[  1   6 812  81  77  13  60  38  13 195  50 227  51]\n",
      "Input: <start> sometimes she tried talking to him about india <end>\n",
      "Predicted translation: ['<start> वह कभीकभी उससे भारत की बात करने की कोशिश किया करती थी']\n",
      "Epoch 50 Batch 0 Loss 0.0448 Accuracy 0.3504\n",
      "Epoch 50 Batch 50 Loss 0.0688 Accuracy 0.3101\n",
      "Epoch 50 Batch 100 Loss 0.0803 Accuracy 0.3077\n",
      "Saving checkpoint for epoch 50 at /content/drive/MyDrive/training_checkpoints/transformer/ckpt-21\n",
      "Epoch 50 Loss 0.0816 Accuracy 0.3066\n",
      "Time taken for 1 epoch: 5.317030668258667 secs\n",
      "\n",
      "<start> the man who is standing there is my father <end>\n",
      "[[1, 3, 86, 126, 8, 428, 43, 8, 13, 67, 2]]\n",
      "[1, 1, 3, 86, 126, 8, 428, 43, 8, 13, 67, 2, 2]\n",
      "[  1 140  18 680 111  99  27 226  11]\n",
      "Input: <start> the man who is standing there is my father <end>\n",
      "Predicted translation: ['<start> वहाँ पर खड़े हुए वे मेरे पिता हैं']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "\n",
    "    for (batch, (inp, tar)) in enumerate(train_dataset):\n",
    "        train_step(inp, tar)\n",
    "\n",
    "        if batch % 50 == 0:\n",
    "            print ('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n",
    "              epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n",
    "\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        ckpt_save_path = ckpt_manager.save()\n",
    "        print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
    "                                                             ckpt_save_path))\n",
    "\n",
    "    print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1,\n",
    "                                                train_loss.result(),\n",
    "                                                train_accuracy.result()))\n",
    "\n",
    "    print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))\n",
    "\n",
    "    # try a translation to see where we at\n",
    "    try:\n",
    "        translate(None, plot=True)\n",
    "    except Exception:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595f26bc",
   "metadata": {
    "id": "595f26bc"
   },
   "source": [
    "## Model evaluation\n",
    "\n",
    "The following steps are used for evaluation:\n",
    "\n",
    "* Encode the input sentence using our chinese tokenizer (`tokenizer_zh`). Moreover, add the start and end sentinel tokens so the input is equivalent to what the model is trained with. This is the encoder input.\n",
    "* The decoder input is the `start token == tokenizer_en.vocab_size`.\n",
    "* Calculate the padding masks and the look ahead masks.\n",
    "* The `decoder` then outputs the predictions by looking at the `encoder output` and its own output (self-attention).\n",
    "* Select the last word and calculate the argmax of that.\n",
    "* Concatentate the predicted word to the decoder input as pass it to the decoder.\n",
    "* In this approach, the decoder predicts the next word based on the previous words it predicted.\n",
    "\n",
    "Note: The model used here has less capacity to keep the example relatively faster so the predictions maybe less right. To reproduce the results in the original Transformer paper, use the entire dataset and base transformer model or transformer XL, by changing our hyperparameters above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f08d6da3",
   "metadata": {
    "id": "f08d6da3"
   },
   "outputs": [],
   "source": [
    "def evaluate(inp_sentence):\n",
    "    #start_token = [tokenizer_pt.vocab_size]\n",
    "    #end_token = [tokenizer_pt.vocab_size + 1]\n",
    "\n",
    "    #inp_sentence = start_token + tokenizer_pt.encode(inp_sentence) + end_token\n",
    "    #inp_sentence = [targ_lang.word_index['<start>']]\n",
    "    #inp_sentence.extend(inp_sentence)\n",
    "    #inp_sentence.append(targ_lang.word_index['<end>'])\n",
    "    inp_sentence = [targ_lang.word_index['<start>']] + inp_sentence[0] + [targ_lang.word_index['<end>']]\n",
    "    print(inp_sentence)\n",
    "    encoder_input = tf.expand_dims(inp_sentence, 0)\n",
    "\n",
    "    #decoder_input = [tokenizer_en.vocab_size]\n",
    "    decoder_input = [targ_lang.word_index['<start>']]\n",
    "    output = tf.expand_dims(decoder_input, 0)\n",
    "\n",
    "    for i in range(max_length_targ):\n",
    "        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
    "            encoder_input, output)\n",
    "\n",
    "        # predictions.shape == (batch_size, seq_len, vocab_size)\n",
    "        predictions, attention_weights = transformer(encoder_input,\n",
    "                                                     output,\n",
    "                                                     False,\n",
    "                                                     enc_padding_mask,\n",
    "                                                     combined_mask,\n",
    "                                                     dec_padding_mask)\n",
    "\n",
    "        # select the last word from the seq_len dimension\n",
    "        predictions = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n",
    "\n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "        # return the result if the predicted_id is equal to the end token\n",
    "        if predicted_id == targ_lang.word_index['<end>']:\n",
    "            return tf.squeeze(output, axis=0), attention_weights\n",
    "\n",
    "        # concatentate the predicted_id to the output which is given to the decoder\n",
    "        # as its input.\n",
    "        output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "    return tf.squeeze(output, axis=0), attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "882cbaef",
   "metadata": {
    "id": "882cbaef"
   },
   "outputs": [],
   "source": [
    "def plot_attention_weights(attention, sentence, result, layer):\n",
    "    fig = plt.figure(figsize=(16, 8))\n",
    "\n",
    "    #sentence = tokenizer_pt.encode(sentence)\n",
    "    sentence = inp_lang.texts_to_sequences([sentence])\n",
    "\n",
    "    attention = tf.squeeze(attention[layer], axis=0)\n",
    "\n",
    "    for head in range(attention.shape[0]):\n",
    "        ax = fig.add_subplot(2, 4, head+1)\n",
    "\n",
    "        # plot the attention weights\n",
    "        ax.matshow(attention[head][:-1, :], cmap='viridis')\n",
    "\n",
    "        fontdict = {'fontsize': 10}\n",
    "\n",
    "        ax.set_xticks(range(len(sentence)+2))\n",
    "        ax.set_yticks(range(len(result)))\n",
    "\n",
    "        ax.set_ylim(len(result)-1.5, -0.5)\n",
    "\n",
    "        #ax.set_xticklabels(\n",
    "        #    ['<start>']+[tokenizer_pt.decode([i]) for i in sentence]+['<end>'],\n",
    "        #    fontdict=fontdict, rotation=90)\n",
    "        #ax.set_xticklabels(\n",
    "        #    ['<start>'] + [inp_lang.sequences_to_texts([i]) for i in sentence] + ['<end>'],\n",
    "        #    fontdict=fontdict, rotation=90)\n",
    "        xticks = ['<start>']\n",
    "        words = [inp_lang.sequences_to_texts([i]) for i in sentence]\n",
    "        xticks.extend(words[0][0].split(' '))\n",
    "        xticks.append('<end>')\n",
    "        print('xticks:',xticks)\n",
    "        ax.set_xticklabels(\n",
    "            xticks,\n",
    "            fontdict=fontdict, rotation=90)\n",
    "\n",
    "\n",
    "        print(result.numpy())\n",
    "        twords = [targ_lang.sequences_to_texts([result.numpy()])]\n",
    "        print(twords)\n",
    "        twords = twords[0][0].split(' ')\n",
    "        pwords = pinyin_jyutping_sentence.pinyin(' '.join(twords[1:]))\n",
    "        print(pwords)\n",
    "        yticks = [] #['<start>']\n",
    "        yticks.extend(pwords.split(' '))\n",
    "        yticks = [t for t in yticks if t]\n",
    "        print('yticks:',yticks)\n",
    "        #ax.set_yticklabels([tokenizer_en.decode([i]) for i in result\n",
    "        #                    if i < tokenizer_en.vocab_size],\n",
    "        #                   fontdict=fontdict)\n",
    "        #ax.set_yticklabels([targ_lang.sequences_to_texts([i]) for i in result\n",
    "        #                    if i < targ_lang.num_words],\n",
    "        #                   fontdict=fontdict)\n",
    "        ax.set_yticklabels(yticks,\n",
    "                           fontdict=fontdict)\n",
    "\n",
    "        ax.set_xlabel('Head {}'.format(head+1))\n",
    "\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bbcb8ef2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bbcb8ef2",
    "outputId": "f2166a3d-86ac-4914-f02c-ec1decc56807"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<start>', 'i', 'will', 'go', 'there', '<end>']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = inp_lang.texts_to_sequences([\"i will go there\"])\n",
    "xticks = ['<start>']\n",
    "words = [inp_lang.sequences_to_texts([i]) for i in sentence]\n",
    "xticks.extend(words[0][0].split(' '))\n",
    "xticks.append('<end>')\n",
    "xticks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f1d3a81f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f1d3a81f",
    "outputId": "0acef313-bad5-43c8-96d0-57c887a88021"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> you keep a dog COMMA dont you <end>\n",
      "[[1, 6, 158, 7, 183, 12, 36, 6, 2]]\n"
     ]
    }
   ],
   "source": [
    "sentence = en[np.random.choice(len(en))]\n",
    "print(sentence)\n",
    "sentence_seq = inp_lang.texts_to_sequences([sentence])\n",
    "print(sentence_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3d14b8aa",
   "metadata": {
    "id": "3d14b8aa"
   },
   "outputs": [],
   "source": [
    "def translate(sentence=None, plot=''):\n",
    "    if sentence is None:\n",
    "        sentence = en[np.random.choice(len(en))]\n",
    "    print(sentence)\n",
    "    sentence_seq = inp_lang.texts_to_sequences([sentence])\n",
    "    print(sentence_seq)\n",
    "\n",
    "    result, attention_weights = evaluate(sentence_seq)\n",
    "    print(result.numpy())\n",
    "\n",
    "    #predicted_sentence = tokenizer_en.decode([i for i in result\n",
    "    #                                        if i < tokenizer_en.vocab_size])\n",
    "    predicted_sentence = targ_lang.sequences_to_texts([result.numpy()])\n",
    "\n",
    "    print('Input: {}'.format(sentence))\n",
    "    print('Predicted translation: {}'.format(predicted_sentence))\n",
    "\n",
    "    if plot:\n",
    "        plot_attention_weights(attention_weights, sentence, result, plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e0f46e71",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e0f46e71",
    "outputId": "5c7f8107-cc76-403f-a8f5-93ceeed31cf0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 16, 8, 7, 230, 27, 18, 5, 2]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[targ_lang.word_index['<start>']] + [[16, 8, 7, 230, 27, 18, 5]][0] + [targ_lang.word_index['<end>']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ff344431",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ff344431",
    "outputId": "ca9d6729-246b-4c6a-ae7e-17cff7fb7079"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i want to clean the house before my parents return\n",
      "[[5, 59, 4, 354, 3, 113, 140, 13, 290, 544]]\n",
      "[1, 5, 59, 4, 354, 3, 113, 140, 13, 290, 544, 2]\n",
      "[   1    8   35 2349    9  121  237    7   89   63  284   56  129   20]\n",
      "Input: i want to clean the house before my parents return\n",
      "Predicted translation: ['<start> मैं अपने पापामम्मी के वापस आने से पहले घर साफ़ करना चाहता हूँ']\n"
     ]
    }
   ],
   "source": [
    "translate(\"i want to clean the house before my parents return\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "_ZLuEVwhPank",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_ZLuEVwhPank",
    "outputId": "6d8ac257-fb0b-414a-dc58-55bc30871bc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the man who is standing there is my father\n",
      "[[3, 86, 126, 8, 428, 43, 8, 13, 67]]\n",
      "[1, 3, 86, 126, 8, 428, 43, 8, 13, 67, 2]\n",
      "[  1 140  18 680 111  99  27 226  11]\n",
      "Input: the man who is standing there is my father\n",
      "Predicted translation: ['<start> वहाँ पर खड़े हुए वे मेरे पिता हैं']\n"
     ]
    }
   ],
   "source": [
    "translate(\"the man who is standing there is my father\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "2INzIksiPdKT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2INzIksiPdKT",
    "outputId": "d84b3322-1ed2-4acd-fd27-939b183bacba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i like watching tv after dinner\n",
      "[[5, 35, 368, 318, 209, 333]]\n",
      "[1, 5, 35, 368, 318, 209, 333, 2]\n",
      "[  1  12 161  10 136 219   9 230  14 131  16]\n",
      "Input: i like watching tv after dinner\n",
      "Predicted translation: ['<start> मुझे रात को खाना खाने के बाद क्या करते हो']\n"
     ]
    }
   ],
   "source": [
    "translate(\"i like watching tv after dinner\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
