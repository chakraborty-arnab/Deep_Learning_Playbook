{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60f01d73",
   "metadata": {
    "id": "60f01d73"
   },
   "source": [
    "# Assignment 8 - Language Translation (English - Hindi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe09020e",
   "metadata": {
    "id": "fe09020e"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from string import digits\n",
    "import tensorflow as tf\n",
    "import re\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68788062",
   "metadata": {
    "id": "68788062"
   },
   "source": [
    "## Read language text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "emPJqrQ5XO5_",
   "metadata": {
    "id": "emPJqrQ5XO5_"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('hind-eng_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "HhR5OgvOJQLL",
   "metadata": {
    "id": "HhR5OgvOJQLL"
   },
   "outputs": [],
   "source": [
    "df['hindi']=df['hindi'].replace('।','',regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a6581fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[['hindi','english']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bH817kH0Jjat",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "bH817kH0Jjat",
    "outputId": "1e37e72b-f784-4075-d702-f1a25be2817b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hindi</th>\n",
       "      <th>english</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>वाह</td>\n",
       "      <td>wow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>बचाओ</td>\n",
       "      <td>help</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>उछलो</td>\n",
       "      <td>jump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>कूदो</td>\n",
       "      <td>jump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>छलांग</td>\n",
       "      <td>jump</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hindi english\n",
       "0    वाह     wow\n",
       "1   बचाओ    help\n",
       "2   उछलो    jump\n",
       "3   कूदो    jump\n",
       "4  छलांग    jump"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "mxdmW0Z0bzLj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "mxdmW0Z0bzLj",
    "outputId": "80920d39-6cf2-4fb4-b398-c5dbc4ed7faf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hindi</th>\n",
       "      <th>english</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2862</th>\n",
       "      <td>जिन यात्रियों को दुर्घटना मे चोट आई थी उन्हे अ...</td>\n",
       "      <td>the passengers who were injured in the acciden...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2863</th>\n",
       "      <td>लोकतंत्र सरकार का सबसे घिनौना रूप है COMMA अगर...</td>\n",
       "      <td>democracy is the worst form of government COMM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2864</th>\n",
       "      <td>अगर मेरा बेटा ट्रेफ़िक हादसे में नहीं मारा गया...</td>\n",
       "      <td>if my boy had not been killed in the traffic a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2865</th>\n",
       "      <td>जब मैं बच्चा था COMMA मुझे कीड़ों को छूने से क...</td>\n",
       "      <td>when i was a kid COMMA touching bugs didnt bot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2866</th>\n",
       "      <td>आप जिस वाक्य का अनुवाद कर रहे हैं COMMA उस ही ...</td>\n",
       "      <td>make a good translation of the sentence that y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  hindi  \\\n",
       "2862  जिन यात्रियों को दुर्घटना मे चोट आई थी उन्हे अ...   \n",
       "2863  लोकतंत्र सरकार का सबसे घिनौना रूप है COMMA अगर...   \n",
       "2864  अगर मेरा बेटा ट्रेफ़िक हादसे में नहीं मारा गया...   \n",
       "2865  जब मैं बच्चा था COMMA मुझे कीड़ों को छूने से क...   \n",
       "2866  आप जिस वाक्य का अनुवाद कर रहे हैं COMMA उस ही ...   \n",
       "\n",
       "                                                english  \n",
       "2862  the passengers who were injured in the acciden...  \n",
       "2863  democracy is the worst form of government COMM...  \n",
       "2864  if my boy had not been killed in the traffic a...  \n",
       "2865  when i was a kid COMMA touching bugs didnt bot...  \n",
       "2866  make a good translation of the sentence that y...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f33436",
   "metadata": {
    "id": "13f33436"
   },
   "source": [
    "## Preprocess text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed816f40",
   "metadata": {
    "id": "ed816f40"
   },
   "source": [
    "##### Filter to only keep sentences with word counts between 5 to 100 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "Jiy4rLru-iIl",
   "metadata": {
    "id": "Jiy4rLru-iIl"
   },
   "outputs": [],
   "source": [
    "df_preprocessed = df[['english','hindi']].rename(columns={'english':'English','hindi':'Hindi'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57b60138",
   "metadata": {
    "id": "57b60138"
   },
   "outputs": [],
   "source": [
    "# Filter the DataFrame to only keep sentences with word counts between 5 to 100 words\n",
    "filtered_df_by_word_count = df_preprocessed[\n",
    "    (df_preprocessed['English'].str.split().str.len() >= 5) &\n",
    "    (df_preprocessed['English'].str.split().str.len() <= 100) &\n",
    "    (df_preprocessed['Hindi'].str.split().str.len() >= 5) &\n",
    "    (df_preprocessed['Hindi'].str.split().str.len() <= 100)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29bfb67c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "29bfb67c",
    "outputId": "446df2ec-5817-4cff-ab30-7a3b7109311e"
   },
   "outputs": [],
   "source": [
    "filtered_df_by_word_count.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33acc121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>Hindi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>he has a hat on</td>\n",
       "      <td>उसने टोपी पहनी हुई है</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no COMMA i didnt go</td>\n",
       "      <td>नहीं COMMA मैं नहीं गया था</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>he came to see me</td>\n",
       "      <td>वह मुझसे मिलने आया था</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>he is after a job</td>\n",
       "      <td>वह किसी नौकरी के पीछे पड़ा है</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i can drive a car</td>\n",
       "      <td>मैं गाड़ी चला सकता हूँ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               English                          Hindi\n",
       "0      he has a hat on          उसने टोपी पहनी हुई है\n",
       "1  no COMMA i didnt go     नहीं COMMA मैं नहीं गया था\n",
       "2    he came to see me          वह मुझसे मिलने आया था\n",
       "3    he is after a job  वह किसी नौकरी के पीछे पड़ा है\n",
       "4    i can drive a car         मैं गाड़ी चला सकता हूँ"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df_by_word_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e733530",
   "metadata": {
    "id": "4e733530"
   },
   "outputs": [],
   "source": [
    "lines = filtered_df_by_word_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec04394",
   "metadata": {
    "id": "fec04394"
   },
   "source": [
    "## Tokenize the data\n",
    "##### Adding start and end tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa7d3e36",
   "metadata": {
    "id": "fa7d3e36"
   },
   "outputs": [],
   "source": [
    "def preprocess_sentence(w):\n",
    "    w = w.strip()\n",
    "\n",
    "    # adding a start and an end token to the sentence\n",
    "    # so that the model know when to start and stop predicting.\n",
    "    w = '<start> ' + w + ' <end>'\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef99dff",
   "metadata": {
    "id": "6ef99dff"
   },
   "source": [
    "##### In Transformer, we add beginning and end of sentence sentinels to *both* languages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "063511bd",
   "metadata": {
    "id": "063511bd"
   },
   "outputs": [],
   "source": [
    "def create_full_dataset():\n",
    "    sentence_pairs = [[preprocess_sentence(l[0]), preprocess_sentence(l[1])] for l in lines.values]\n",
    "    return zip(*sentence_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9511dffe",
   "metadata": {
    "id": "9511dffe"
   },
   "outputs": [],
   "source": [
    "def tokenize(lang):\n",
    "    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "    lang_tokenizer.fit_on_texts(lang)\n",
    "\n",
    "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
    "\n",
    "    return tensor, lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "661f22ab",
   "metadata": {
    "id": "661f22ab"
   },
   "outputs": [],
   "source": [
    "def load_full_dataset():\n",
    "    # creating cleaned input, output pairs\n",
    "    inp_lang, targ_lang = create_full_dataset()\n",
    "\n",
    "    input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
    "    target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
    "\n",
    "    return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "436a8481",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "436a8481",
    "outputId": "771b845a-b4a0-4a4c-c3c7-fdb0c9cf8d04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> he has a hat on <end>\n",
      "<start> उसने टोपी पहनी हुई है <end>\n"
     ]
    }
   ],
   "source": [
    "en, hi = create_full_dataset()\n",
    "print(en[0])\n",
    "print(hi[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "01fd62f7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "01fd62f7",
    "outputId": "64250ba5-69a4-403e-accf-19b8a09c217e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29, 25)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_examples = len(lines)\n",
    "input_tensor, target_tensor, inp_lang, targ_lang = load_full_dataset()\n",
    "\n",
    "# Calculate max_length of the target tensors\n",
    "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]\n",
    "max_length_targ, max_length_inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "36321b37",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "36321b37",
    "outputId": "8fdcab84-4bce-42e6-89ca-e9926b003914"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 words in the Input Language vocabulary:\n",
      "<start>\n",
      "<end>\n",
      "the\n",
      "to\n",
      "i\n",
      "you\n",
      "a\n",
      "is\n",
      "he\n",
      "of\n",
      "First 10 words in the Target Language vocabulary:\n",
      "<start>\n",
      "<end>\n",
      "है\n",
      "में\n",
      "नहीं\n",
      "वह\n",
      "से\n",
      "मैं\n",
      "के\n",
      "को\n"
     ]
    }
   ],
   "source": [
    "# Function to print vocabulary words\n",
    "def print_vocab_words(tokenizer, language_name, num_words=10):\n",
    "    # Extract the word_index from the tokenizer\n",
    "    word_index = tokenizer.word_index\n",
    "\n",
    "    # Get the first 'num_words' words from the vocabulary\n",
    "    first_words = list(word_index.keys())[:num_words]\n",
    "\n",
    "    print(f\"First {num_words} words in the {language_name} vocabulary:\")\n",
    "    for word in first_words:\n",
    "        print(word)\n",
    "\n",
    "# 'inp_lang' and 'targ_lang' are tokenizer objects for input and target languages, respectively\n",
    "print_vocab_words(inp_lang, \"Input Language\")\n",
    "print_vocab_words(targ_lang, \"Target Language\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b80f0a9e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b80f0a9e",
    "outputId": "1946e1c1-cad0-4bf5-8681-85f13d429457"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input language vocabulary size: 2156\n",
      "Target language vocabulary size: 2556\n"
     ]
    }
   ],
   "source": [
    "# Vocabulary size for the input language\n",
    "input_vocab_size = len(inp_lang.word_index) + 1  # Adding 1 because indexing starts from 1\n",
    "print(f\"Input language vocabulary size: {input_vocab_size}\")\n",
    "\n",
    "# Vocabulary size for the target language\n",
    "target_vocab_size = len(targ_lang.word_index) + 1  # Adding 1 because indexing starts from 1\n",
    "print(f\"Target language vocabulary size: {target_vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e2e63f5b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e2e63f5b",
    "outputId": "2d99f0d5-959b-47ce-b02b-0c52a47abe79"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1881, 25), (209, 25), (1881, 29), (209, 29))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating training and validation sets using an 90-10 split\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(\n",
    "    input_tensor, target_tensor, test_size=0.1)\n",
    "\n",
    "input_tensor_train.shape, input_tensor_val.shape, target_tensor_train.shape, target_tensor_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "77473ee8",
   "metadata": {
    "id": "77473ee8"
   },
   "outputs": [],
   "source": [
    "def convert(lang, tensor):\n",
    "    for t in tensor:\n",
    "        if t!=0:\n",
    "            print (\"%d ----> %s\" % (t, lang.index_word[t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2cc65cfe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2cc65cfe",
    "outputId": "baf4bf7f-9cfa-4e1c-a377-b85a6a933ecb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Language; index to word mapping\n",
      "1 ----> <start>\n",
      "9 ----> he\n",
      "8 ----> is\n",
      "508 ----> getting\n",
      "425 ----> along\n",
      "34 ----> with\n",
      "22 ----> his\n",
      "1680 ----> employees\n",
      "2 ----> <end>\n",
      "\n",
      "Target Language; index to word mapping\n",
      "1 ----> <start>\n",
      "6 ----> वह\n",
      "35 ----> अपने\n",
      "638 ----> कर्मचारियों\n",
      "9 ----> के\n",
      "64 ----> साथ\n",
      "283 ----> अच्छे\n",
      "7 ----> से\n",
      "2013 ----> निभता\n",
      "3 ----> है\n",
      "2 ----> <end>\n"
     ]
    }
   ],
   "source": [
    "print (\"Input Language; index to word mapping\")\n",
    "convert(inp_lang, input_tensor_train[1])\n",
    "print ()\n",
    "print (\"Target Language; index to word mapping\")\n",
    "convert(targ_lang, target_tensor_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9c1bce3a",
   "metadata": {
    "id": "9c1bce3a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-06 19:04:31.177625: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3 Pro\n",
      "2024-04-06 19:04:31.177703: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 18.00 GB\n",
      "2024-04-06 19:04:31.177723: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 6.00 GB\n",
      "2024-04-06 19:04:31.178008: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-04-06 19:04:31.178379: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 16\n",
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "\n",
    "vocab_inp_size = len(inp_lang.word_index)+1\n",
    "vocab_tar_size = len(targ_lang.word_index)+1\n",
    "\n",
    "dataset_train = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset_train = dataset_train.batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "dataset_val = tf.data.Dataset.from_tensor_slices((input_tensor_val, target_tensor_val)).shuffle(BUFFER_SIZE)\n",
    "dataset_val = dataset_val.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "31803de3",
   "metadata": {
    "id": "31803de3"
   },
   "outputs": [],
   "source": [
    "train_dataset = dataset_train\n",
    "val_dataset = dataset_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b79378",
   "metadata": {
    "id": "42b79378"
   },
   "source": [
    "## Positional encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fb4a6ee2",
   "metadata": {
    "id": "fb4a6ee2"
   },
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "    return pos * angle_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "00a2f21a",
   "metadata": {
    "id": "00a2f21a"
   },
   "outputs": [],
   "source": [
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                          np.arange(d_model)[np.newaxis, :],\n",
    "                          d_model)\n",
    "\n",
    "    # apply sin to even indices in the array; 2i\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "\n",
    "    # apply cos to odd indices in the array; 2i+1\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8c6730",
   "metadata": {
    "id": "9d8c6730"
   },
   "source": [
    "## Masking pad tokens in the input and future tokens in the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7f8e13e3",
   "metadata": {
    "id": "7f8e13e3"
   },
   "outputs": [],
   "source": [
    "def create_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "\n",
    "    # add extra dimensions to add the padding\n",
    "    # to the attention logits.\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6379d98d",
   "metadata": {
    "id": "6379d98d"
   },
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask  # (seq_len, seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387f49f7",
   "metadata": {
    "id": "387f49f7"
   },
   "source": [
    "## Scaled dot product attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d9f7d3e3",
   "metadata": {
    "id": "d9f7d3e3"
   },
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    \"\"\"Calculate the attention weights.\n",
    "    q, k, v must have matching leading dimensions.\n",
    "    k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
    "    The mask has different shapes depending on its type(padding or look ahead)\n",
    "    but it must be broadcastable for addition.\n",
    "\n",
    "    Args:\n",
    "    q: query shape == (..., seq_len_q, depth)\n",
    "    k: key shape == (..., seq_len_k, depth)\n",
    "    v: value shape == (..., seq_len_v, depth_v)\n",
    "    mask: Float tensor with shape broadcastable\n",
    "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "    output, attention_weights\n",
    "    \"\"\"\n",
    "\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "    # scale matmul_qk\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "    # add the mask to the scaled tensor.\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)\n",
    "\n",
    "    # softmax is normalized on the last axis (seq_len_k) so that the scores add up to 1.\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "    output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed413825",
   "metadata": {
    "id": "ed413825"
   },
   "source": [
    "## Multi-head attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "000fecda",
   "metadata": {
    "id": "000fecda"
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.wq = tf.keras.layers.Dense(d_model)\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        self.wv = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"Split the last dimension into (num_heads, depth).\n",
    "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "        \"\"\"\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "\n",
    "        q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "        k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "        v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "\n",
    "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "\n",
    "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "            q, k, v, mask)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "\n",
    "        concat_attention = tf.reshape(scaled_attention,\n",
    "                                      (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc23a930",
   "metadata": {
    "id": "cc23a930"
   },
   "source": [
    "## Pointwise feed forward network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9cac212e",
   "metadata": {
    "id": "9cac212e"
   },
   "outputs": [],
   "source": [
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "    return tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
    "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd2a9b7",
   "metadata": {
    "id": "1cd2a9b7"
   },
   "source": [
    "# Encoder and decoder\n",
    "\n",
    "Now we're ready to talk about the encoder and decoder. In that, the transformer model follows the same general pattern as our standard sequence to sequence with attention model, albeit with multiple layers:\n",
    "\n",
    "* The input sentence is passed through `N` encoder layers that generate an output for each word/token in the sequence.\n",
    "* The decoder attends on the encoder's output and its own input (self-attention) to predict the next word.\n",
    "\n",
    "## Encoder layer\n",
    "\n",
    "Each encoder layer consists of sublayers:\n",
    "\n",
    "1. Multi-head attention (with padding mask)\n",
    "2. Pointwise feed forward networks\n",
    "\n",
    "Each of these sublayers has a residual connection around it followed by a layer normalization. Residual connections help in avoiding the vanishing gradient problem in deep networks.\n",
    "\n",
    "The output of each sublayer is `LayerNorm(x + Sublayer(x))`. The normalization is done on the `d_model` (last) axis. There are N encoder layers in the transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "43da4792",
   "metadata": {
    "id": "43da4792"
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, training, mask):\n",
    "        attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        return out2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23d11bf",
   "metadata": {
    "id": "a23d11bf"
   },
   "source": [
    "## Decoder layer\n",
    "\n",
    "Each decoder layer consists of sublayers:\n",
    "\n",
    "1. Masked multi-head attention (with look ahead mask and padding mask)\n",
    "2. Multi-head attention (with padding mask): V (value) and K (key) receive the *encoder output* as inputs. Q (query) receives the *output from the masked multi-head attention sublayer.*\n",
    "3. Pointwise feed forward networks\n",
    "\n",
    "Each of these sublayers has a residual connection around it followed by a layer normalization. The output of each sublayer is `LayerNorm(x + Sublayer(x))`. The normalization is done on the `d_model` (last) axis.\n",
    "\n",
    "There are N decoder layers in the transformer.\n",
    "\n",
    "As Q receives the output from decoder's first attention block, and K receives the encoder output, the attention weights represent the importance given to the decoder's input based on the encoder's output. In other words, the decoder predicts the next word by looking at the encoder output and self-attending to its own output. See the demonstration above in the scaled dot product attention section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ef91485d",
   "metadata": {
    "id": "ef91485d"
   },
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "\n",
    "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
    "        # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
    "        attn1 = self.dropout1(attn1, training=training)\n",
    "        out1 = self.layernorm1(attn1 + x)\n",
    "\n",
    "        attn2, attn_weights_block2 = self.mha2(\n",
    "            enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
    "        attn2 = self.dropout2(attn2, training=training)\n",
    "        out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
    "        ffn_output = self.dropout3(ffn_output, training=training)\n",
    "        out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        return out3, attn_weights_block1, attn_weights_block2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ac7bee",
   "metadata": {
    "id": "99ac7bee"
   },
   "source": [
    "## Encoder\n",
    "\n",
    "And now we can talk about the encoder.\n",
    "\n",
    "The `Encoder` consists of:\n",
    "1.   Word2vec semantic embedding\n",
    "2.   Positional Encoding\n",
    "3.   N encoder layers (what we coded above)\n",
    "\n",
    "The input is fed through an embedding which is then summed with  positional encoding. The output of this summation is the input to the encoder layers. The output of the encoder is the input to the decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5e9ef996",
   "metadata": {
    "id": "5e9ef996"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding,\n",
    "                                                self.d_model)\n",
    "\n",
    "\n",
    "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate)\n",
    "                           for _ in range(num_layers)]\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, training, mask):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "\n",
    "        # adding embedding and position encoding.\n",
    "        x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x, training, mask)\n",
    "\n",
    "        return x  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02b2065",
   "metadata": {
    "id": "d02b2065"
   },
   "source": [
    "## Decoder\n",
    "\n",
    " The `Decoder` consists of:\n",
    "1.   Word2vec embedding of the target sequence\n",
    "2.   Positional Encoding\n",
    "3.   N decoder layers\n",
    "\n",
    "The target sequence is fed through an embedding and summed with positional encoding. The output of this summation is the input to the decoder layers. The output of the decoder is the input to our final linear layer, which we mention in the wrapper Transformer layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ea9cbeaf",
   "metadata": {
    "id": "ea9cbeaf"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "\n",
    "        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate)\n",
    "                           for _ in range(num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, enc_output, training,\n",
    "           look_ahead_mask, padding_mask):\n",
    "\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        attention_weights = {}\n",
    "\n",
    "        x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
    "                                                 look_ahead_mask, padding_mask)\n",
    "\n",
    "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
    "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
    "\n",
    "        # x.shape == (batch_size, target_seq_len, d_model)\n",
    "        return x, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f0b018",
   "metadata": {
    "id": "d9f0b018"
   },
   "source": [
    "## Create the Transformer\n",
    "\n",
    "Transformer consists of the encoder, decoder and our final affine (linear) `Dense` layer. The output of the decoder is the input to the linear layer and its output is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ae76755f",
   "metadata": {
    "id": "ae76755f"
   },
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "               target_vocab_size, pe_input, pe_target, rate=0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(num_layers, d_model, num_heads, dff,\n",
    "                               input_vocab_size, pe_input, rate)\n",
    "\n",
    "        self.decoder = Decoder(num_layers, d_model, num_heads, dff,\n",
    "                               target_vocab_size, pe_target, rate)\n",
    "\n",
    "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "\n",
    "    def call(self, inp, tar, training, enc_padding_mask,\n",
    "           look_ahead_mask, dec_padding_mask):\n",
    "\n",
    "        enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
    "\n",
    "        # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
    "        dec_output, attention_weights = self.decoder(\n",
    "            tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
    "\n",
    "        final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
    "\n",
    "        return final_output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e57579",
   "metadata": {
    "id": "55e57579"
   },
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "695d2f1c",
   "metadata": {
    "id": "695d2f1c"
   },
   "outputs": [],
   "source": [
    "num_layers = 4\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "input_vocab_size = len(inp_lang.word_index) + 1\n",
    "target_vocab_size = len(targ_lang.word_index) + 1\n",
    "dropout_rate = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5a1bed",
   "metadata": {
    "id": "5a5a1bed"
   },
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5dc94612",
   "metadata": {
    "id": "5dc94612"
   },
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        step = tf.cast(step, tf.float32)\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8e4679c8",
   "metadata": {
    "id": "8e4679c8"
   },
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.legacy.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n",
    "                                     epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9fb393a3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "9fb393a3",
    "outputId": "d93ed856-7d90-4945-9d31-d8682b48cc8e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp_learning_rate_schedule = CustomSchedule(d_model)\n",
    "\n",
    "plt.plot(temp_learning_rate_schedule(tf.range(40000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4042b49a",
   "metadata": {
    "id": "4042b49a"
   },
   "source": [
    "## Loss and metrics\n",
    "\n",
    "Since the target sequences are padded, it is important to apply a padding mask when calculating the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e838e0d9",
   "metadata": {
    "id": "e838e0d9"
   },
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "687f573b",
   "metadata": {
    "id": "687f573b"
   },
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "52da641e",
   "metadata": {
    "id": "52da641e"
   },
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "    name='train_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95647e0d",
   "metadata": {
    "id": "95647e0d"
   },
   "source": [
    "## Training and checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6cbefd37",
   "metadata": {
    "id": "6cbefd37"
   },
   "outputs": [],
   "source": [
    "transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
    "                          input_vocab_size, target_vocab_size,\n",
    "                          pe_input=input_vocab_size,\n",
    "                          pe_target=target_vocab_size,\n",
    "                          rate=dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "985aac85",
   "metadata": {
    "id": "985aac85"
   },
   "outputs": [],
   "source": [
    "def create_masks(inp, tar):\n",
    "    # Encoder padding mask\n",
    "    enc_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    # Used in the 2nd attention block in the decoder.\n",
    "    # This padding mask is used to mask the encoder outputs.\n",
    "    dec_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    # Used in the 1st attention block in the decoder.\n",
    "    # It is used to pad and mask future tokens in the input received by\n",
    "    # the decoder.\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "    dec_target_padding_mask = create_padding_mask(tar)\n",
    "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "\n",
    "    return enc_padding_mask, combined_mask, dec_padding_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa4a9eb",
   "metadata": {
    "id": "eaa4a9eb"
   },
   "source": [
    "Create the checkpoint path and the checkpoint manager. This will be used to save checkpoints every `n` epochs.\n",
    "\n",
    "Create the `transformer` folder in your `~/data/training_checkpoints` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "07c211c0",
   "metadata": {
    "id": "07c211c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest checkpoint restored!!\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = \"training_checkpoints/transformer\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
    "                           optimizer=optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print ('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6b81dd",
   "metadata": {
    "id": "bc6b81dd"
   },
   "source": [
    "The target is divided into `tar_inp` and `tar_real`. `tar_inp` is passed as an input to the decoder. `tar_real` is that same input shifted by 1: At each location in `tar_input`, `tar_real` contains the  next token that should be predicted.\n",
    "\n",
    "For example, `sentence` = \"<start> A lion in the jungle is sleeping <end>\"\n",
    "\n",
    "`tar_inp` =  `<start> A lion in the jungle is sleeping`\n",
    "\n",
    "`tar_real` = `A lion in the jungle is sleeping <end>`\n",
    "\n",
    "The transformer is an auto-regressive model: it makes predictions one word at a time, and uses its output so far to decide what word to predict next.\n",
    "\n",
    "During training, this example uses teacher-forcing\n",
    "\n",
    "(as in the [text generation tutorial](./text_generation.ipynb)).\n",
    "\n",
    "Teacher forcing is passing the true output to the next time step regardless of what the model predicts at the current time step.\n",
    "\n",
    "As the transformer predicts each word, **self-attention** allows it to look at the previous words in the input sequence to better predict the next word.\n",
    "\n",
    "To prevent the model from peaking at the expected output, the model uses a look-ahead mask."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6edc3f",
   "metadata": {
    "id": "1b6edc3f"
   },
   "source": [
    "This is our training step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "97477592",
   "metadata": {
    "id": "97477592"
   },
   "outputs": [],
   "source": [
    "# The @tf.function trace-compiles train_step into a TF graph for faster\n",
    "# execution. The function specializes to the precise shape of the argument\n",
    "# tensors. To avoid re-tracing due to the variable sequence lengths or variable\n",
    "# batch sizes (the last batch is smaller), use input_signature to specify\n",
    "# more generic shapes.\n",
    "\n",
    "# for our corpus\n",
    "train_step_signature = [\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int32),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int32),\n",
    "]\n",
    "\n",
    "@tf.function(input_signature=train_step_signature)\n",
    "def train_step(inp, tar):\n",
    "    tar_inp = tar[:, :-1]\n",
    "    tar_real = tar[:, 1:]\n",
    "\n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, _ = transformer(inp, tar_inp,\n",
    "                                     True,\n",
    "                                     enc_padding_mask,\n",
    "                                     combined_mask,\n",
    "                                     dec_padding_mask)\n",
    "        loss = loss_function(tar_real, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, transformer.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(tar_real, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cfc2d0",
   "metadata": {
    "id": "06cfc2d0"
   },
   "source": [
    "## We'll be running translations inline as we're training the transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e8d30217",
   "metadata": {
    "id": "e8d30217"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "22f55ab8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "22f55ab8",
    "outputId": "7ba1f79e-c827-4e85-f400-2585a93b8a18"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-06 19:18:59.843626: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 1.3885 Accuracy 0.2723\n",
      "Epoch 1 Batch 50 Loss 2.2436 Accuracy 0.1827\n",
      "Epoch 1 Batch 100 Loss 2.1769 Accuracy 0.1874\n",
      "Epoch 1 Loss 2.1263 Accuracy 0.1910\n",
      "Time taken for 1 epoch: 22.291985273361206 secs\n",
      "\n",
      "[1, 1, 246, 272, 7, 527, 324, 2, 2]\n",
      "Input: <start> thats really a great idea <end>\n",
      "Predicted translation: ['<start> वह अच्छा कमा लेता है']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "\n",
    "    for (batch, (inp, tar)) in enumerate(train_dataset):\n",
    "        train_step(inp, tar)\n",
    "\n",
    "        if batch % 50 == 0:\n",
    "            print ('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n",
    "              epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n",
    "\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        ckpt_save_path = ckpt_manager.save()\n",
    "        print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
    "                                                             ckpt_save_path))\n",
    "\n",
    "    print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1,\n",
    "                                                train_loss.result(),\n",
    "                                                train_accuracy.result()))\n",
    "\n",
    "    print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))\n",
    "\n",
    "    # try a translation to see where we at\n",
    "    try:\n",
    "        translate(None, plot=True)\n",
    "    except Exception:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595f26bc",
   "metadata": {
    "id": "595f26bc"
   },
   "source": [
    "## Model evaluation\n",
    "\n",
    "The following steps are used for evaluation:\n",
    "\n",
    "* Encode the input sentence using our chinese tokenizer (`tokenizer_zh`). Moreover, add the start and end sentinel tokens so the input is equivalent to what the model is trained with. This is the encoder input.\n",
    "* The decoder input is the `start token == tokenizer_en.vocab_size`.\n",
    "* Calculate the padding masks and the look ahead masks.\n",
    "* The `decoder` then outputs the predictions by looking at the `encoder output` and its own output (self-attention).\n",
    "* Select the last word and calculate the argmax of that.\n",
    "* Concatentate the predicted word to the decoder input as pass it to the decoder.\n",
    "* In this approach, the decoder predicts the next word based on the previous words it predicted.\n",
    "\n",
    "Note: The model used here has less capacity to keep the example relatively faster so the predictions maybe less right. To reproduce the results in the original Transformer paper, use the entire dataset and base transformer model or transformer XL, by changing our hyperparameters above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f08d6da3",
   "metadata": {
    "id": "f08d6da3"
   },
   "outputs": [],
   "source": [
    "def evaluate(inp_sentence):\n",
    "\n",
    "    inp_sentence = [targ_lang.word_index['<start>']] + inp_sentence[0] + [targ_lang.word_index['<end>']]\n",
    "    print(inp_sentence)\n",
    "    encoder_input = tf.expand_dims(inp_sentence, 0)\n",
    "\n",
    "    #decoder_input = [tokenizer_en.vocab_size]\n",
    "    decoder_input = [targ_lang.word_index['<start>']]\n",
    "    output = tf.expand_dims(decoder_input, 0)\n",
    "\n",
    "    for i in range(max_length_targ):\n",
    "        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
    "            encoder_input, output)\n",
    "\n",
    "        # predictions.shape == (batch_size, seq_len, vocab_size)\n",
    "        predictions, attention_weights = transformer(encoder_input,\n",
    "                                                     output,\n",
    "                                                     False,\n",
    "                                                     enc_padding_mask,\n",
    "                                                     combined_mask,\n",
    "                                                     dec_padding_mask)\n",
    "\n",
    "        # select the last word from the seq_len dimension\n",
    "        predictions = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n",
    "\n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "        # return the result if the predicted_id is equal to the end token\n",
    "        if predicted_id == targ_lang.word_index['<end>']:\n",
    "            return tf.squeeze(output, axis=0), attention_weights\n",
    "\n",
    "        # concatentate the predicted_id to the output which is given to the decoder\n",
    "        # as its input.\n",
    "        output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "    return tf.squeeze(output, axis=0), attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "882cbaef",
   "metadata": {
    "id": "882cbaef"
   },
   "outputs": [],
   "source": [
    "def plot_attention_weights(attention, sentence, result, layer):\n",
    "    fig = plt.figure(figsize=(16, 8))\n",
    "\n",
    "    sentence = inp_lang.texts_to_sequences([sentence])\n",
    "\n",
    "    attention = tf.squeeze(attention[layer], axis=0)\n",
    "\n",
    "    for head in range(attention.shape[0]):\n",
    "        ax = fig.add_subplot(2, 4, head+1)\n",
    "\n",
    "        # plot the attention weights\n",
    "        ax.matshow(attention[head][:-1, :], cmap='viridis')\n",
    "\n",
    "        fontdict = {'fontsize': 10}\n",
    "\n",
    "        ax.set_xticks(range(len(sentence)+2))\n",
    "        ax.set_yticks(range(len(result)))\n",
    "\n",
    "        ax.set_ylim(len(result)-1.5, -0.5)\n",
    "\n",
    "        xticks = ['<start>']\n",
    "        words = [inp_lang.sequences_to_texts([i]) for i in sentence]\n",
    "        xticks.extend(words[0][0].split(' '))\n",
    "        xticks.append('<end>')\n",
    "        print('xticks:',xticks)\n",
    "        ax.set_xticklabels(\n",
    "            xticks,\n",
    "            fontdict=fontdict, rotation=90)\n",
    "\n",
    "\n",
    "        print(result.numpy())\n",
    "        twords = [targ_lang.sequences_to_texts([result.numpy()])]\n",
    "        print(twords)\n",
    "        twords = twords[0][0].split(' ')\n",
    "        pwords = pinyin_jyutping_sentence.pinyin(' '.join(twords[1:]))\n",
    "        print(pwords)\n",
    "        yticks = [] #['<start>']\n",
    "        yticks.extend(pwords.split(' '))\n",
    "        yticks = [t for t in yticks if t]\n",
    "        print('yticks:',yticks)\n",
    "\n",
    "        ax.set_yticklabels(yticks,\n",
    "                           fontdict=fontdict)\n",
    "\n",
    "        ax.set_xlabel('Head {}'.format(head+1))\n",
    "\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bbcb8ef2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bbcb8ef2",
    "outputId": "f2166a3d-86ac-4914-f02c-ec1decc56807"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<start>', 'i', 'will', 'go', 'there', '<end>']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = inp_lang.texts_to_sequences([\"i will go there\"])\n",
    "xticks = ['<start>']\n",
    "words = [inp_lang.sequences_to_texts([i]) for i in sentence]\n",
    "xticks.extend(words[0][0].split(' '))\n",
    "xticks.append('<end>')\n",
    "xticks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f1d3a81f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f1d3a81f",
    "outputId": "0acef313-bad5-43c8-96d0-57c887a88021"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> all the students look up to him <end>\n",
      "[[1, 41, 3, 547, 536, 45, 4, 28, 2]]\n"
     ]
    }
   ],
   "source": [
    "sentence = en[np.random.choice(len(en))]\n",
    "print(sentence)\n",
    "sentence_seq = inp_lang.texts_to_sequences([sentence])\n",
    "print(sentence_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "3d14b8aa",
   "metadata": {
    "id": "3d14b8aa"
   },
   "outputs": [],
   "source": [
    "def translate(sentence=None, plot=''):\n",
    "    if sentence is None:\n",
    "        sentence = en[np.random.choice(len(en))]\n",
    "    sentence_seq = inp_lang.texts_to_sequences([sentence])\n",
    "    result, attention_weights = evaluate(sentence_seq)\n",
    "\n",
    "    predicted_sentence = targ_lang.sequences_to_texts([result.numpy()])\n",
    "    print('Input: {}'.format(sentence))\n",
    "    print('Predicted translation: {}'.format(predicted_sentence))\n",
    "\n",
    "    if plot:\n",
    "        plot_attention_weights(attention_weights, sentence, result, plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ff344431",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ff344431",
    "outputId": "ca9d6729-246b-4c6a-ae7e-17cff7fb7079"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 5, 59, 4, 354, 3, 113, 140, 13, 290, 544, 2]\n",
      "Input: i want to clean the house before my parents return\n",
      "Predicted translation: ['<start> मैं अपने पापामम्मी के वापस आने से पहले घर साफ़ करना चाहता हूँ']\n"
     ]
    }
   ],
   "source": [
    "translate(\"i want to clean the house before my parents return\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "_ZLuEVwhPank",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_ZLuEVwhPank",
    "outputId": "6d8ac257-fb0b-414a-dc58-55bc30871bc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 86, 126, 8, 428, 43, 8, 13, 67, 2]\n",
      "Input: the man who is standing there is my father\n",
      "Predicted translation: ['<start> वहाँ पर खड़े हुए वे मेरे पिता हैं']\n"
     ]
    }
   ],
   "source": [
    "translate(\"the man who is standing there is my father\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2INzIksiPdKT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2INzIksiPdKT",
    "outputId": "d84b3322-1ed2-4acd-fd27-939b183bacba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 5, 35, 368, 318, 209, 333, 2]\n",
      "Input: i like watching tv after dinner\n",
      "Predicted translation: ['<start> मुझे रात को खाना खाने के बाद क्या करते हो']\n"
     ]
    }
   ],
   "source": [
    "translate(\"i like watching tv after dinner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d691ee3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
